TO DO
=====

Reporting in the methods section
--------------------------------

- Adjust how the baseline results are reported now that we are using the 
single-analysis approach throughout
- Add a single footnote that succintly states that we have made a number of
choices for the analysis and presentation of results, but that we have checked
other possible approaches and they yielded compatible results. Then refer 
reader to the appendix for more information.
- Caveats have to do with current implementation of GAMMs.
- Communicate that we have cared about how to analyze the data and how to
present it.


Effect of proficiency and comparison to native speakers
-------------------------------------------------------

TFJ came up with a nice approach (slightly edited from his email 2018-09-14):


i) take a model of the natives that you already have (this could be done while
considering trial, i.e., the model from question 1, or without trial, i.e., the
baseline model).

ii) then use the predict function of the gamm (mgcv::predict.gam) to predict
the data of all non-native participants (i.e., new data with new individuals).
Store the predicted probability of the actually observed outcome of each trial. 

iii) log the probability of each trial and then sum these log-probabilities
by-participant, giving you log-likelihoods (LL) of each non-native participant
being generated by the native model.

i.e, 

data of non-natives$predicted <- predict(model of native, newdata = data of non-natives )

data of non-natives$ll = log(ifelse(actual outcome == 1, predicted, 1-predicted)

data of non-native %>%
group_by(Subject, Priming condition, Proficiency) %>%
summarise(ll = sum(ll))

iv) plot these LLs (y-axis) against proficiency (x-axis), separated by priming
condition (3 colors).
fit 3 (color) or 1 (joint) smoother through this to see whether LL increases
with proficiency.
To the far right one can plot the LL of the native data (under the native model)
to illustrate variability in the native group.

v) if we so fancy, one can analyze the LLs with a gamm or glmm, but perhaps the
visualization does the job?


Remarks:
- in predict.gam function, use argument "type = 'response'"
- play around with the parameter "unconditional" (can be TRUE or FALSE), which
specifies whether the smoothing parameter uncertainty corrected covariance
matrix is used (see help(predict.gam))




Parallelize to speed up model fitting
-------------------------

To speed up GAMM fitting, Florian recommends to parallelize, using the parallel
 package. A snippet of code by Florian featuring the relevant functions (from
 his email from 2018-09-16):

nc <- 8                                    ## cluster size
if (detectCores() > 1) {
    cat(paste0("Making cluster with ", nc, " cores.\n"))
    cl <- makeCluster(min(nc, detectCores())) 
    ## could also use makeForkCluster, but read warnings first!
  } else cl <- NULL

cat("Fitting model ... ")
tic()

g = bam(
  TargetFix ~ Contrast + te(Time, Trial, by = Contrast) +
    s(Subject, Time, Trial, bs = "fs") + s(Audio, Time, bs = "fs"),
  data = mydata,
  family = binomial(),
  cluster = cl
)



Reporting the analysis
----------------------

Check out "Analysis approach" section in Fraundorf & Jaeger (2016, p.35)


Discussion
----------

- Generally stronger overall priming in L2ers vs natives
- Why upward trend (path verbs) and downward trend (manner verbs) over course of experiment? See Kootstra&Doedens 2016
