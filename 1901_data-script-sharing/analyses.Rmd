---
title: "Replication of analyses reported in Montero-Melis & Jaeger (2019) in *BLC*"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Introduction
============

This knitr document accompanies the paper

Montero-Melis, G., & Jaeger, T. F. (2019). Changing expectations mediate
adaptation in L2 production. Submitted to *Bilingualism: Language and Cognition*

For details, please refer to the main text and the Supplementary Online 
Material.


Set up working space
====================

Load libraries
--------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 4, fig.width = 5)
```

```{r, include = TRUE, echo = TRUE, warning = FALSE, message = FALSE}
library(dplyr)
packageVersion('dplyr')
library(tidyr)
packageVersion('tidyr')  # useful for gather() to convert from wide to long
library(mgcv)  # GAMs and GAMMs (Wood 2006)
packageVersion('mgcv')
library(itsadug)
packageVersion('itsadug')  # Visualizing GAMMs
library(lme4)
packageVersion('lme4')
library(ggplot2)
packageVersion('ggplot2')
library(GGally)
packageVersion('GGally')
# library(boot)  # for inv.logit()
# packageVersion('boot')
library(knitr)  # for kable()
packageVersion('knitr')
# library(lazyeval)  # lazy evaluation used in bysubj() function [summarise_]
# packageVersion('lazyeval')
# library(effects)
# library(xtable)
```

```{r}
# Make sure you are in the folder where all the scripts and data are located,
# otherwise the script won't run.
getwd()
```


Convenience functions
---------------------

Because some models take a long time to fit, we use the self-mande convenience
function `load_or_fit`. This function first checks whether a model with a given
name already exists as a `.rda` file in the subfolder `fitted_models/`. If it does,
it loads it, otherwise it fits it and saves it to that folder.

```{r}
# Source function used to load models if they have already been saved, rather
# than fitting them anew each time the script is called.
source("load_or_fit_fnc.R")
# This function expects a subfolder "fitted_models/"; create it
dir.create(file.path("fitted_models/"))
```

Format table for GLMM output

```{r}
# create a neat table of the summary of fixed effects of a mixed model	
glmm_tb <- function(fm) {	
  m <- round(summary(fm)$coefficients, 3)	
  tb <- as.data.frame(m)	
  names(tb) <- c("Estimate", "SE", "z-value", "p-value")	
  kable(tb)	
}	
```


Plot GLMM estimates (baseline condition):

```{r}
# Function that plots mixed model-estimates in logit space from baseline
# conditions, including speaker estimates
source("plot_glmm_fnc.R")
```



Load data and set up data frames for analyses
-------------------------------------------

```{r}
# load data
d <- read.csv('data.csv', fileEncoding = 'UTF-8', stringsAsFactors = TRUE)
# Make sure Subject is a factor
d$Subject <- factor(d$Subject)
# in Group, let the native speakers (NS) be the reference group
d$Group <- factor(d$Group, levels = c('NS', 'L2'))
head(d, 3)
# load participant information 
# NB: Accidentally, no audio data was recorded for Subject 14 (L2), so this
# participant is omitted from all participant descriptors as well.
ppts <- read.csv("participant-info.csv", fileEncoding = "UTF-8", 
                 stringsAsFactors = TRUE)
head(ppts, 3)
tail(ppts, 3)  # L2 proficiency-related variables only available for L2ers
```

### Set up data for models (GLMMs and GAMMs)

We will do two things:

1) In each model, we want to allow for two comparisons: a) Path verb use in the
Baseline condition vs Path verb use in the Path-primed condition, and b) Manner
verb use in the Baseline condition vs Manner verb use in the Manner-primed
condition.
2) In addition, we want to define the correct data type and coding schemes for the
different factors.

```{r}
# Convert data to long format: each description will now have two rows, one for
# each value of VerbType (P_V = Path verb; M_V = Manner verb); note that these
# two rows were previously two different columns showing whether what was 
# encoded in the main verb in a given description encoded was path, manner,
# both or neither (see data frame d above).
d_long <- gather(d, VerbType, Used, P_V : M_V)

# Create copy of long data set, which we will further process for model fitting
d_mod <- d_long

# Combine VerbType (Path/Manner) and Condition (baseline/primed) into a single
# factor -- this is needed for the GAMMs. (The way to analyze crossed factors
# is to combine their levels into a single factor, see Wood's comment here:
# http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm)
d_mod$VbType_Cond <- with(d_mod, interaction(VerbType, Condition))	

# In order to make the relevant comparisons (see point 1 here above), baseline
# participants have to be compared twice, once for their path verb use to path-
# primed participants, once for their manner verb use to manner-primed 
# participants. This means that each of the two rows defined by VerbType will
# be used in one of the comparisons. The following renaming allows us to
# fit random by-subject smooths for each of those comparisons:
d_mod$Subject <- with(d_mod, interaction(Subject, VerbType))	

## Subset data for model fitting:
# We are removing observations that	contain irrelevant comparisons given our
# research question, namely those that correspond to path verbs produced in the
# manner-primed condition or to manner	verbs produced in the path-primed 
# condition.
d_mod <- d_mod %>% filter(! VbType_Cond %in% c("P_V.Manner", "M_V.Path"))
# drop unused factor levels and order levels correctly
d_mod$VbType_Cond <- factor(d_mod$VbType_Cond, 
                            levels = c("P_V.Baseline", "P_V.Path", "M_V.Baseline",
                                       "M_V.Manner"))
# drop unused factors for subject (important for random effects estimation)
d_mod$Subject <- factor(d_mod$Subject)
# Condition recoded as a binary factor (Path/Manner become "Primed")
d_mod$Condition_bin <- d_mod$Condition
levels(d_mod$Condition_bin)[levels(d_mod$Condition_bin) %in% c("Path", "Manner")] <- "Primed"	
```


Coding scheme for factors:

```{r}
# define factor coding scheme (contrast coding)
# group
contrasts(d_mod$Group) <- - contr.sum(2)
colnames(contrasts(d_mod$Group)) <- "L2_vs_NS"
contrasts(d_mod$Group)
# Verb type
d_mod$VerbType <- factor(d_mod$VerbType)
contrasts(d_mod$VerbType) <- contr.sum(2)
colnames(contrasts(d_mod$VerbType)) <- "M_vs_P"
contrasts(d_mod$VerbType)
# Condition_bin contrast coding	
contrasts(d_mod$Condition_bin) <- - contr.sum(2)
colnames(contrasts(d_mod$Condition_bin)) <- "Primed_vs_Baseline"	
contrasts(d_mod$Condition_bin)	
```

Show data frame

```{r}
head(d_mod)
str(d_mod)
```



Participant descriptors
=======================

## As reported in the main text (Method section)

Number of participants by group:

```{r}
# Number of participants by group that go into the analysis (note data for
# one L2 speaker is missing because of recording failure)
table(ppts$Group)
```


Participant age:

```{r}
# age
ppts %>%
  group_by(Group) %>%
  summarise(Mage = mean(Age, na.rm = T), SDage = sd(Age, na.rm = T))
```


Learners' age of onset for learning Spanish 

```{r}
# Mean and SD
ppts %>%
  filter(Group == "L2") %>%
  summarise(M  = round(mean(L2_AoO, na.rm = TRUE), 2), 
            SD = round(sd(L2_AoO, na.rm = TRUE), 2))
# range
range(ppts$L2_AoO, na.rm = TRUE)
```



Scores on offline cloze test ('proficiency score'):

```{r}
# Cloze scores
round(mean(ppts$ClozeScore, na.rm=T), 1)
round(sd(ppts$ClozeScore, na.rm=T), 1)
# By condition
ppts %>% 
  filter(Group == "L2") %>% 
  group_by(Condition) %>%
  summarise(M_profic = mean(ClozeScore), 
            SD = sd(ClozeScore))
```


Difference in L2 proficiency across conditions (one-way ANOVA):

```{r}
# one-way ANOVA
ppts %>% 
  filter(Group == "L2") %>%
  aov(ClozeScore ~ Condition, data = .) %>%
  summary
```


Computerized vocabulary task, which was deliberately easy (see main text).
(Data for this task is missing from one participant due to experimenter error.)

```{r}
# Scores on vocabulary task
round(mean(ppts$VocabTaskAcc, na.rm=T), 3)
round(sd(ppts$VocabTaskAcc, na.rm=T), 4)
# By condition
ppts %>% 
  filter(Group == "L2") %>% 
  group_by(Condition) %>%
  summarise(M_profic = mean(VocabTaskAcc, na.rm = TRUE), 
            SD = sd(VocabTaskAcc, na.rm = TRUE))
```



## Participant information reported in the Supplementary Online Information (S2)

### Measures of L2 proficiency


Distribution of Cloze scores

```{r}
ppts %>% filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, colour = Condition)) +
  geom_density() +
  geom_rug() +
  facet_grid(Condition ~ .)
```


Numerical summaries of L2 variables potentially related to L2 proficiency:

```{r, warning=FALSE}
ppts %>% filter(Group == "L2") %>% 
  select(ClozeScore, L2_SelfRating, L2_AoO, L2_instruction_years, VocabTaskAcc) %>%
  summary
```


Correlation between different L2-related measures that were collected:

```{r, warning=FALSE, fig.width=6.5, fig.height=5}
ppts %>% filter(Group == "L2") %>% 
  select(ClozeScore, L2_SelfRating, L2_AoO, L2_instruction_years, VocabTaskAcc) %>%
  ggpairs(upper = list(
    continuous = wrap('cor', method = "spearman")
  ))
```



### Other background information

Gender distribution of the participants:

```{r}
with(ppts, table(Group, Gender))
```


Age distribution:

```{r, fig.width=6, warning=FALSE}
ppts %>% 
  ggplot(aes(x = Age, colour = Condition)) +
  geom_density() +
  geom_rug() +
  facet_grid(Condition ~ Group)
```


Results and discussion
======================


Baseline condition: Native and L2 speakersâ€™ lexical preferences in the absence of priming
------------------------------------------------------------------------------------


### Set up data set for GLMM


```{r, echo = T}
# Subset data from baseline condition only
d_basel <- d_long %>% 
  filter(Condition == "Baseline") %>%
  select(Subject : ClozeScore, VerbType, Used)
# Use contrast coding to compare groups...
contrasts(d_basel$Group) <- - contr.sum(2)
colnames(contrasts(d_basel$Group)) <- "L2_vs_NS"
contrasts(d_basel$Group)
# ... and Verb type
d_basel$VerbType <- factor(d_basel$VerbType)
contrasts(d_basel$VerbType) <- contr.sum(2)
colnames(contrasts(d_basel$VerbType)) <- "M_vs_P"
contrasts(d_basel$VerbType)
# show
head(d_basel, 3); tail(d_basel, 3)
```



### Reported in main text

Table 3 in main text:

```{r}
# Descriptive data for all analysed conditions (only relevant comparisons).
# Note the table was appropriately formatted in report.
d_mod %>%
  # filter(! VbType_Cond %in% c("P_V.Manner", "M_V.Path")) %>%
  group_by(VerbType, Group, Condition) %>%
  summarise(Occurrences = sum(Used),
            TotalN = n(),
            Percentage = round(100 * sum(Used) / n(), 1)) %>%
  kable
```



```{r, echo = TRUE}
# load model or fit
# First define the expression to be passed to load_or_fit()
glmm_basel.expr <- "glmer(Used ~ VerbType * Group +
(1 + VerbType | Subject) + (1 + VerbType * Group | VideoName),
data = d_basel, family = 'binomial',
control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"

# Now pass it to the function (see source code for the inner workings)
load_or_fit("glmm_basel", glmm_basel.expr)
```


Fixed effects estimates:

```{r}
# output table
glmm_tb(glmm_basel)
```


Plot the results:

```{r}
# the function is defined in analysis/functions/plot_glmm_fnc.R
plot_basel(glmm_basel, d_basel, nb_sims = 500)
```





### Reported in Supplementary Online Material

Model summary:

```{r}
summary(glmm_basel)
```



Trial-by-trial adaptation of native speakers (Question 1)
---------------------------------------------------------


### Reported in main text


### Reported in Supplementary Online Material



Trial-by-trial adaptation of L2 learners (Question 2)
-----------------------------------------------------


### Reported in main text


### Reported in Supplementary Online Material




Effect of L2 proficiency on trial-by-trial adaptation (Question 3)
------------------------------------------------------------------

### Reported in main text


### Reported in Supplementary Online Material





Session info
============

```{r}
sessionInfo()
```


