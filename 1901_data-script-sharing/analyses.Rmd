---
title: "Replication of analyses reported in Montero-Melis & Jaeger (2019) in *BLC*"
author: '[Guillermo Montero-Melis](https://www.mpi.nl/people/montero-melis-guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
---


Introduction
============

This knitr document accompanies the paper

Montero-Melis, G., & Jaeger, T. F. (2019). Changing expectations mediate
adaptation in L2 production. Submitted to *Bilingualism: Language and Cognition*

For details, please refer to the main text and the Supplementary Online 
Material.


Set up working space
====================

Load libraries
--------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 4, fig.width = 5)
```

```{r, include = TRUE, echo = TRUE, warning = FALSE, message = FALSE}
library(dplyr)
packageVersion('dplyr')
library(tidyr)
packageVersion('tidyr')  # useful for gather() to convert from wide to long
library(mgcv)  # GAMs and GAMMs (Wood 2006)
packageVersion('mgcv')
library(itsadug)
packageVersion('itsadug')  # Visualizing GAMMs
library(lme4)
packageVersion('lme4')
library(ggplot2)
packageVersion('ggplot2')
library(GGally)
packageVersion('GGally')
# library(boot)  # for inv.logit()
# packageVersion('boot')
library(knitr)  # for kable()
packageVersion('knitr')
# library(lazyeval)  # lazy evaluation used in bysubj() function [summarise_]
# packageVersion('lazyeval')
# library(effects)
# library(xtable)
```

```{r}
# Make sure you are in the folder where all the scripts and data are located,
# otherwise the script won't run.
getwd()
```


Convenience functions
---------------------

Because some models take a long time to fit, we use the self-mande convenience
function `load_or_fit`. This function first checks whether a model with a given
name already exists as a `.rda` file in the subfolder `fitted_models/`. If it does,
it loads it, otherwise it fits it and saves it to that folder.

```{r}
# Source function used to load models if they have already been saved, rather
# than fitting them anew each time the script is called.
source("load_or_fit_fnc.R")
# This function expects a subfolder "fitted_models/"; create it
dir.create(file.path("fitted_models/"))
```

Format table for GLMM output

```{r}
# create a neat table of the summary of fixed effects of a mixed model	
glmm_tb <- function(fm) {	
  m <- round(summary(fm)$coefficients, 3)	
  tb <- as.data.frame(m)	
  names(tb) <- c("Estimate", "SE", "z-value", "p-value")	
  kable(tb)	
}	
```


Plot GLMM estimates (baseline condition):

```{r}
# Function that plots mixed model-estimates in logit space from baseline
# conditions, including speaker estimates
source("plot_glmm_fnc.R")
```


Plot GAMM estimates:

```{r}
# Two functions to a) plot adaptation effects for native and L2 speakers from
# GAMMs, and b) plot the effects by L2 speakers' proficiency.
source("plot_gams_fnc.R")
```


Global variables for figures
----------------------------

```{r}
# adjust figure heght/width when not going with default (espec. for 2x2 plots)
myfighe_NS_L2 <- 6
myfighe_L2_prof <- 6
myfigwi <- 7
```


Load data and set up data frames for analyses
-------------------------------------------

```{r}
# load data
d <- read.csv('data.csv', fileEncoding = 'UTF-8', stringsAsFactors = TRUE)
# Make sure Subject is a factor
d$Subject <- factor(d$Subject)
# in Group, let the native speakers (NS) be the reference group
d$Group <- factor(d$Group, levels = c('NS', 'L2'))
head(d, 3)
# load participant information 
# NB: Accidentally, no audio data was recorded for Subject 14 (L2), so this
# participant is omitted from all participant descriptors as well.
ppts <- read.csv("participant-info.csv", fileEncoding = "UTF-8", 
                 stringsAsFactors = TRUE)
head(ppts, 3)
tail(ppts, 3)  # L2 proficiency-related variables only available for L2ers
```

### Set up data for models (GLMMs and GAMMs)

We will do two things:

1) In each model, we want to allow for two comparisons: a) Path verb use in the
Baseline condition vs Path verb use in the Path-primed condition, and b) Manner
verb use in the Baseline condition vs Manner verb use in the Manner-primed
condition.
2) In addition, we want to define the correct data type and coding schemes for the
different factors.

```{r}
# Convert data to long format: each description will now have two rows, one for
# each value of VerbType (P_V = Path verb; M_V = Manner verb); note that these
# two rows were previously two different columns showing whether what was 
# encoded in the main verb in a given description encoded was path, manner,
# both or neither (see data frame d above).
d_long <- gather(d, VerbType, Used, P_V : M_V)

# Create copy of long data set, which we will further process for model fitting
d_mod <- d_long

# Combine VerbType (Path/Manner) and Condition (baseline/primed) into a single
# factor -- this is needed for the GAMMs. (The way to analyze crossed factors
# is to combine their levels into a single factor, see Wood's comment here:
# http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm)
d_mod$VbType_Cond <- with(d_mod, interaction(VerbType, Condition))	

# In order to make the relevant comparisons (see point 1 here above), baseline
# participants have to be compared twice, once for their path verb use to path-
# primed participants, once for their manner verb use to manner-primed 
# participants. This means that each of the two rows defined by VerbType will
# be used in one of the comparisons. The following renaming allows us to
# fit random by-subject smooths for each of those comparisons:
d_mod$Subject <- with(d_mod, interaction(Subject, VerbType))	

# Subset data for model fitting:
# We remove observations that	contain irrelevant comparisons given our research
# question, namely those that correspond to path verbs produced in the manner-
# primed condition or to manner	verbs produced in the path-primed condition.
d_mod <- d_mod %>% filter(! VbType_Cond %in% c("P_V.Manner", "M_V.Path"))
# drop unused factor levels and order levels correctly
d_mod$VbType_Cond <- factor(d_mod$VbType_Cond, 
                            levels = c("P_V.Baseline", "P_V.Path", "M_V.Baseline",
                                       "M_V.Manner"))
# drop unused factors for subject (important for random effects estimation)
d_mod$Subject <- factor(d_mod$Subject)
# Condition recoded as a binary factor (Path/Manner become "Primed")
d_mod$Condition_bin <- d_mod$Condition
levels(d_mod$Condition_bin)[levels(d_mod$Condition_bin) %in% c("Path", "Manner")] <- "Primed"	
```


Coding scheme for factors:

```{r}
# define factor coding scheme (contrast coding)
# group
contrasts(d_mod$Group) <- - contr.sum(2)
colnames(contrasts(d_mod$Group)) <- "L2_vs_NS"
contrasts(d_mod$Group)
# Verb type
d_mod$VerbType <- factor(d_mod$VerbType)
contrasts(d_mod$VerbType) <- contr.sum(2)
colnames(contrasts(d_mod$VerbType)) <- "M_vs_P"
contrasts(d_mod$VerbType)
# Condition_bin contrast coding	
contrasts(d_mod$Condition_bin) <- - contr.sum(2)
colnames(contrasts(d_mod$Condition_bin)) <- "Primed_vs_Baseline"	
contrasts(d_mod$Condition_bin)	
```

Show data frame

```{r}
head(d_mod)
str(d_mod)
```



Participant descriptors
=======================

## As reported in the main text (Method section)

Number of participants by group:

```{r}
# Number of participants by group that go into the analysis (note data for
# one L2 speaker is missing because of recording failure)
table(ppts$Group)
```


Participant age:

```{r}
# age
ppts %>%
  group_by(Group) %>%
  summarise(Mage = mean(Age, na.rm = T), SDage = sd(Age, na.rm = T))
```


Learners' age of onset for learning Spanish 

```{r}
# Mean and SD
ppts %>%
  filter(Group == "L2") %>%
  summarise(M  = round(mean(L2_AoO, na.rm = TRUE), 2), 
            SD = round(sd(L2_AoO, na.rm = TRUE), 2))
# range
range(ppts$L2_AoO, na.rm = TRUE)
```



Scores on offline cloze test ('proficiency score'):

```{r}
# Cloze scores
round(mean(ppts$ClozeScore, na.rm=T), 1)
round(sd(ppts$ClozeScore, na.rm=T), 1)
# By condition
ppts %>% 
  filter(Group == "L2") %>% 
  group_by(Condition) %>%
  summarise(M_profic = mean(ClozeScore), 
            SD = sd(ClozeScore))
```


Difference in L2 proficiency across conditions (one-way ANOVA):

```{r}
# one-way ANOVA
ppts %>% 
  filter(Group == "L2") %>%
  aov(ClozeScore ~ Condition, data = .) %>%
  summary
```


Computerized vocabulary task, which was deliberately easy (see main text).
(Data for this task is missing from one participant due to experimenter error.)

```{r}
# Scores on vocabulary task
round(mean(ppts$VocabTaskAcc, na.rm=T), 3)
round(sd(ppts$VocabTaskAcc, na.rm=T), 4)
# By condition
ppts %>% 
  filter(Group == "L2") %>% 
  group_by(Condition) %>%
  summarise(M_profic = mean(VocabTaskAcc, na.rm = TRUE), 
            SD = sd(VocabTaskAcc, na.rm = TRUE))
```



## Participant information reported in the Supplementary Online Information (S2)

### Measures of L2 proficiency


Distribution of Cloze scores

```{r}
ppts %>% filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, colour = Condition)) +
  geom_density() +
  geom_rug() +
  facet_grid(Condition ~ .)
```


Numerical summaries of L2 variables potentially related to L2 proficiency:

```{r, warning=FALSE}
ppts %>% filter(Group == "L2") %>% 
  select(ClozeScore, L2_SelfRating, L2_AoO, L2_instruction_years, VocabTaskAcc) %>%
  summary
```


Correlation between different L2-related measures that were collected:

```{r, warning=FALSE, fig.width=6.5, fig.height=5}
ppts %>% filter(Group == "L2") %>% 
  select(ClozeScore, L2_SelfRating, L2_AoO, L2_instruction_years, VocabTaskAcc) %>%
  ggpairs(upper = list(
    continuous = wrap('cor', method = "spearman")
  ))
```



### Other background information

Gender distribution of the participants:

```{r}
with(ppts, table(Group, Gender))
```


Age distribution:

```{r, fig.width=6, warning=FALSE}
ppts %>% 
  ggplot(aes(x = Age, colour = Condition)) +
  geom_density() +
  geom_rug() +
  facet_grid(Condition ~ Group)
```


Results and discussion
======================


Baseline condition: Native and L2 speakersâ€™ lexical preferences in the absence of priming
------------------------------------------------------------------------------------


### Set up data set for GLMM


```{r, echo = T}
# Subset data from baseline condition only
d_basel <- d_long %>% 
  filter(Condition == "Baseline") %>%
  select(Subject : ClozeScore, VerbType, Used)
# Use contrast coding to compare groups...
contrasts(d_basel$Group) <- - contr.sum(2)
colnames(contrasts(d_basel$Group)) <- "L2_vs_NS"
contrasts(d_basel$Group)
# ... and Verb type
d_basel$VerbType <- factor(d_basel$VerbType)
contrasts(d_basel$VerbType) <- contr.sum(2)
colnames(contrasts(d_basel$VerbType)) <- "M_vs_P"
contrasts(d_basel$VerbType)
# show
head(d_basel, 3); tail(d_basel, 3)
```



### Reported in main text

Table 3 in main text:

```{r}
# Descriptive data for all analysed conditions (only relevant comparisons).
# Note the table was appropriately formatted in report.
d_mod %>%
  group_by(VerbType, Group, Condition) %>%
  summarise(Occurrences = sum(Used),
            TotalN = n(),
            Percentage = round(100 * sum(Used) / n(), 1)) %>%
  kable
```



```{r, echo = TRUE}
# load model or fit
# First define the expression to be passed to load_or_fit()
glmm_basel.expr <- 
"glmer(Used ~ VerbType * Group + (1 + VerbType | Subject) +
  (1 + VerbType * Group | VideoName),
data = d_basel, family = 'binomial',
control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# Now pass it to the function (see source code for the inner workings)
load_or_fit("glmm_basel", glmm_basel.expr)
```


Fixed effects estimates:

```{r}
# output table
glmm_tb(glmm_basel)
```


Plot the results:

```{r}
# the function is defined in analysis/functions/plot_glmm_fnc.R
plot_basel(glmm_basel, d_basel, nb_sims = 500)
```





### Reported in Supplementary Online Material

Model summary:

```{r}
summary(glmm_basel)
```



Trial-by-trial adaptation of native speakers (Question 1)
---------------------------------------------------------

### Set up data frame:

```{r}
# Subset data to native speaker data only
d_ns <- d_mod %>% filter(Group == "NS")
# drop unused factors for subject (important for gam fitting)
d_ns$Subject <- factor(d_ns$Subject)
# note log-odds of path verbs in baseline condition becomes the reference level
contrasts(d_ns$VbType_Cond)
```


### GAMM specification and fitting


First, we fit a more complex GAMM with by-subject and by-item factor smooths
for Trial (`s(Trial, Subject, bs = 'fs')` and `s(Trial, VideoName, bs = 'fs')`,
respectively).

```{r}
# the expression that is passed to load_or_fit()
gam_ns_itemsmooth.expr <- 
"bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) + 
  s(Trial, Subject, bs = 'fs') + s(Trial, VideoName, bs = 'fs'),
data = d_ns,
family = 'binomial')"
# load model or fit (fitting took about 10 minutes on my laptop)
load_or_fit("gam_ns_itemsmooth", gam_ns_itemsmooth.expr)
```

Model summary:

```{r}
summary(gam_ns_itemsmooth)
```

We can see that the by-subject factor smooth for Trial (`s(Trial, Subject)`)
captures a fair amount of variance, whereas the by-item factor smooth for Trial
(`s(Trial, VideoName)`) does not.
Considering the interpretation of each of these factor smooths, this makes sense.
By-subject factor smooths capture how individual speakers are modifying
their encoding choices as the experiment progresses. One would indeed expect
those preferences to change at the individual level above and beyond the
population-level estimates. For the items, however, the factor smooth is modelling
the same type of changes at the level of the items (i.e., the individual events
being seen). Intuitively one expects less variation here: one would expect that
some items elicit more path encoding while others more manner encoding, but it
is less likely that the encoding preference associated to an item *changes* over
the course of the experiment. That effect should a priori be small if at all
existent. This is how we interpret the small variance associated to the by-item
factor smooth for Trial.

More practically, since factor smooths will take up many degrees of freedom and
slow down model fitting (here, it took twice the amount of time), let us compare
this model with another that has by-item random intercepts instead:

```{r gam_ns}
# the expression that is passed to load_or_fit()
gam_ns.expr <- 
"bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = 'fs') +
  s(VideoName, bs = 're'),
data = d_ns,
family = 'binomial')"
# load model or fit (fitting took about 4.5 minutes on my laptop)
load_or_fit("gam_ns", gam_ns.expr)
```


```{r}
summary(gam_ns)
```

Note that the two models are identical in all coefficient estimates, except for
a very subtle difference for the estimated random effects of items (last line:
`VideoName`). We thus keep the simpler model.


In summary, the model is specified as:

`DV ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're')`

Predictors are:

- `VbType_Cond`: VerbType-Condition interaction as a fixed effect. The four levels
of this variable decompose into two crossed factors:
    - `VerbType`: Indicator variable that defines what is being measured by the DV,
  either the occurrence of path verbs or of manner verbs
    - `Condition`: Primed vs baseline
- `s(Trial, by = VbType_Cond)`: A smooth function of `Trial` allowing the function to differ for each level of Group-Condition (thin plate regression splines, the default)
- `s(Trial, Subject, bs = 'fs')`: Factor smooths for `Subject` to capture non-linear random effects of speakers
- `s(VideoName, bs = 're')`: Random intercepts by items (i.e., `VideoName`)



### Reported in main text


Plot differences between conditions (model estimates):

```{r, fig.height = myfighe_NS_L2, fig.width = myfigwi, echo = TRUE, results = 'hide'}
plot_gam_main(gam_ns, "NS")  # choose this on Linux machine
# On my old computer, the above call threw an warning/error; this was solved by
# the following argument setting:
# plot_gam_main(gam_ns, "NS", mark.diff = FALSE)
```


### Reported in Supplementary Online Material

#### GAMM output

Summary of the GAMM for trial-by-trial adaptation in native speakers:

```{r, results = "asis"}
itsadug::gamtabs(gam_ns, type = "HTML")
```


#### Follow-up analysis (GLMM)

Rationale:

Based on the GAMM analysis, we can see that for native speakers there was a
significant adaptation effect for Manner, but not for Path verbs. However, 
we cannot conclude from one pattern being significant and the other not that
the two *differ* significantly. 
Unfortunately, this type of interaction analysis in a factorial design is 
difficult to implement in the GAM framework we are using (see, e.g.,
[here](http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm)).
We therefore carry out a follow-up mixed logistic regression analysis to address
this interaction, while noting that this is not an ideal solution:
we lose power, either because we model the effect wrongly (assuming linerarity
in a relation that is non-linear) and thus we may not capture the actual signal,
or because we reduce the number of observations to include only data points
that *do* have a linear relationship between predictors and dependent variable.
Here, we adopt this latter approach.

Since GLMMs assume linearity in log-odds space, We have to subset the data
to use only those trials that show an approximately linear relation with the
outcome variable (based on visual inspection). We keep trials 15 through 32.

Subset data:

```{r}
d_ns_lin <- d_ns %>% filter(Trial >= 15)
```


Verify factors are contrast coded and `cTrial` is centred:

```{r}
# Verify factors are contrast coded:
contrasts(d_ns_lin$Condition_bin)
contrasts(d_ns_lin$VerbType)
d_ns_lin$cTrial <- d_ns_lin$Trial - mean(d_ns_lin$Trial)  # centre
round(mean(d_ns_lin$cTrial), 7)  # check
```


In these and all the following GLMMs, we try to stay conceptually close to the
random effects structure used in the GAMMs. This means we will generally
try to fit a model with random by-item and by-subject intercepts, as well as
a random by-subject slope for `cTrial` (corresponding to the smooth term
`s(Trial, Subject, bs = 'fs')` in the GAMMs).

Fit the model:

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_ns_lin.expr <- 
"glmer(Used ~ Condition_bin * VerbType * cTrial + (1 + cTrial | Subject) +
  (1 | VideoName),
data = d_ns_lin, family = 'binomial',
control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_ns_lin", glmm_ns_lin.expr)
```

Model summary:

```{r}
summary(glmm_ns_lin)
```





Trial-by-trial adaptation of L2 learners (Question 2)
-----------------------------------------------------

### Set up data frame:

```{r}
d_l2 <- d_mod %>% filter(Group == "L2")
# drop unused factors for subject (I think this is important for gam fitting)
d_l2$Subject <- factor(d_l2$Subject)
# note log-odds of path verbs in baseline condition becomes the reference level
contrasts(d_l2$VbType_Cond)
```


### GAMM specification and fitting

We proceed analogously as for native speakers (Question 1). We start by fitting
a more complex random structure, we then inspect the coefficients, and if warranted,
we then simplify it and check if anything changes.

```{r}
# the expression that is passed to load_or_fit()
gam_l2_itemsmooth.expr <- 
"bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) + 
  s(Trial, Subject, bs = 'fs') + s(Trial, VideoName, bs = 'fs'),
data = d_l2,
family = 'binomial')"
# load model or fit (fitting took about 13 minutes on my laptop)
load_or_fit("gam_l2_itemsmooth", gam_l2_itemsmooth.expr)
```

Model summary:

```{r}
summary(gam_l2_itemsmooth)
```


```{r gam_l2}
# the expression that is passed to load_or_fit()
gam_l2.expr <- 
"bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = 'fs') +
  s(VideoName, bs = 're'),
data = d_l2,
family = 'binomial')"
# load model or fit (fitting took about 5 minutes on my laptop)
load_or_fit("gam_l2", gam_l2.expr)
```


```{r}
summary(gam_l2)
```

The comparison is very similar to what we observed with native speakers:
The two models are pretty much identical in all coefficient estimates, except
for a difference for the estimated random effects of items (last line: 
`VideoName`), which does not affect the rest of the model. We thus retain and
report the simpler model.


### Reported in main text

Plot differences between conditions (model estimates):

```{r, fig.height = myfighe_NS_L2, fig.width = myfigwi, echo = TRUE, results = 'hide'}
plot_gam_main(gam_l2, "L2")
```


### Reported in Supplementary Online Material

#### GAMM output

Summary of the GAMM for trial-by-trial adaptation in L2 speakers:

```{r, results = "asis"}
itsadug::gamtabs(gam_l2, type = "HTML")
```


#### Follow-up analysis

The rationale for this analysis is analogous to that for the follow-up
analysis on Question 1 above.

Since GLMMs assume linearity in log-odds space, We have to subset the data
to use only those trials that show an approximately linear relation with the
outcome variable (based on visual inspection). We keep trials 1 through 13.

Subset data:

```{r}
d_l2_lin <- d_l2 %>% filter(Trial <= 13)
```

Verify factors are contrast coded and `cTrial` is centred:

```{r}
# Verify factors are contrast coded:
contrasts(d_l2_lin$Condition_bin)
contrasts(d_l2_lin$VerbType)
# recenter cTrial
d_l2_lin$cTrial <- d_l2_lin$Trial - mean(d_l2_lin$Trial) 
round(mean(d_l2_lin$cTrial), 7)  # check
```


Fit the model:

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_l2_lin.expr <- 
"glmer(Used ~ Condition_bin * VerbType * cTrial + (1 + cTrial | Subject) +
  (1 | VideoName),
data = d_l2_lin, family = 'binomial',
control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_l2_lin", glmm_l2_lin.expr)
```


Model summary:

```{r}
summary(glmm_l2_lin)
```







Effect of L2 proficiency on trial-by-trial adaptation (Question 3)
------------------------------------------------------------------

### Data and processing

The data is the same as we used to address Question 2, only now we will use
the predictor `ClozeScore` to measure L2 proficiency.

First rows of the data set:

```{r}
head(d_l2)
```


### GAMM fitting

We start by fitting two models, one with and one without the interaction term
`te(Trial, ClozeScore, by = Condition)`
Using model comparison, we can see if this term significantly improves the model.

Model including 3-way interaction

```{r model_l2prof_with_interac}
# model with interaction
gam_l2prof.expr <- 
"bam(Used ~ VbType_Cond + te(Trial, ClozeScore, by = VbType_Cond) +
  s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're'),
data = d_l2,
family = 'binomial')"
# load model or fit (fitting took about 6.5 minutes on my laptop)
load_or_fit("gam_l2prof", gam_l2prof.expr)
```

Model summary:

```{r}
summary(gam_l2prof)
```


### Reported in main text

Plot differences between conditions (model estimates):

```{r, fig.height = 4, fig.width = 8, echo = TRUE, results = 'hide'}
plot_L2_profic_diff_singlemodel(gam_l2prof, primed_cond = "Path")
plot_L2_profic_diff_singlemodel(gam_l2prof, primed_cond = "Manner")
```


### Reported in Supplementary Online Material


Model output (properly formatted):

```{r, results = "asis"}
itsadug::gamtabs(gam_l2prof, type = "HTML")
```

Plot each comparison showing the two curves (model estimates):

```{r, fig.height = 4, fig.width = 8, echo = TRUE, results = 'hide'}
plot_L2_profic_singlemodel(gam_l2prof, primed_cond = 'Path')
plot_L2_profic_singlemodel(gam_l2prof, primed_cond = 'Manner')
```


### Not reported: difference surfaces

This is another way of visualizing the results, which we did not report
in either the main text or the SOM. These plots are interpreted in an
analogous fashion to normal maps which show altitude as contour lines.
The height of the contours gives the model estimate.

So effectively the plots we report in the main paper (Figure 6) take four
slices of those "hilly landscapes", cut parallel to the x-axis, and rotate
them so that the former altitude is now plotted along the y axis.

Plot difference surfaces:

```{r}
plot_diff2(gam_l2prof, view = c("Trial", "ClozeScore"),
           comp = list(VbType_Cond = c("P_V.Path", "P_V.Baseline")),
           plotCI = TRUE, rm.ranef = TRUE, 
           main = "Path verbs: Path-primed -- baseline")
```

```{r}
plot_diff2(gam_l2prof, view = c("Trial", "ClozeScore"),
           comp = list(VbType_Cond = c("M_V.Manner", "M_V.Baseline")),
           plotCI = TRUE, rm.ranef = TRUE, 
           main = "Manner verbs: Manner-primed -- baseline")
```




Session info
============

```{r}
sessionInfo()
```


