## Run follow-up analyses on Q3, based on suggestion by TFJ to assess the
## likelihood of the L2ers' data under the native speaker model.


# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Conceptual background (email correspondence) ----------------------------
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## I) Initial proposal

## TFJ's email (fre 2018-09-14 22:09 "Re: testing for interactions in GAMs"):

# There's one idea I had just now that I kinda like that we can implement after
# submission. It's very easy to implement:
#   
# i) take a model of the natives that you already have (this could be done
# while considering trial, i.e., the model from question 1, or without trial,
# i.e., the baseline model). 
# 
# ii) then use the predict function of the gamm to predict the data of all
# non-native participants (i.e., new data with new individuals). Store the
# predicted probability of the actually observed outcome of each trial (either
# for the joint analysis or for both of the separate path verb? + manner verb?
# analyses). 
# 
# iii) log the probability of each trial and then sum these log-probabilities
# by-participant, giving you log-likelihoods (LL) of each non-native participant
# being generated by the native model. I.e., 
# 
# data of non-natives$predicted = predict(model of native, newdata = data of non-natives)
# 
# data of non-natives$ll = log(ifelse(actual outcome == 1, predicted, 1-predicted))
#
# data of non-native %>%
#   group_by(Subject, Priming condition) %>%
#   summarise(ll = mean(ll))
#                              
# iv) plot these LLs (y-axis) against proficiency (x-axis), separated by
# priming condition (3 colors). fit 3 (color) or 1 (joint) smoother through
# this to see whether LL increases with proficiency.
# 
# v) if we so fancy, one can analyze the LLs with a gamm or glmm, but perhaps
# the visualization does the job?


## II) Problem

## The procedure suggested above does not work quite at first, as I explain in
## an email (Mon 2018-09-17 17:53 "Re: testing for interactions in GAMs"):

# Regarding your last suggestion for the follow-up on Q3 (comparison of L2ers
# as a function of proficiency and natives using the predict function), the
# following line of code:
#   
# gam_ns_fit_to_L2 <- predict.gam(gam_ns, newdata = d_l2, type = "response")
#   
# yields the error:
# Error in predict.gam(gam_ns, newdata = d_l2, type = "response") : 
#     1.M_V, 10.M_V, 11.M_V, 12.M_V, ... 9.P_V not in original fit
#   
# predict.gam() complains because the L2 subjects are not the same as the 
# natives. This is understandable, since the original model we fit 
# [ Used ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = "fs")
# + s(VideoName, bs = "re") ] 
# estimates factor smooths for each (native) subject.
#   
# It seems like the lme4 version of predict can handle such a scenario by simply
# omitting the random effects when predicting (using the argument “re.form = NA”,
# see this thread), but the predict.gam doesn’t. I tried to follow what I believe
# was suggested in the thread, by fitting the same model for native speakers but
# with the data:
#
# d_ns_all_ppt_levels <- d_ns
# levels(d_ns_all_ppt_levels$Subject) <- c(levels(d_ns$Subject), levels(d_l2$Subject))
# 
# That is, including the levels of the L2ers in the Subject factor, but I could
# not fool gam with this cheap trick.


## III) Solution

## TFJ's email (Tue tis 2018-09-18 22:33 "Re: testing for interactions in GAMs"):

# Luckily, there's a reasonable 'simple' solution:
# 
# 1) make a copy of your non-native data
# 
# 2) override the subject info by randomly assigning native subject IDs, say
# with replacement.
# 
# copy_nonnative_data %<>%
# group_by(Subject) %>%
# mutate(Subject = sample(levels(native_data$Subject), 1, replace = T))
# 
# 3) Do the predict as previously discussed. Get the LLs for each subject.
# Remember them in e.g., a table or data.frame with one row per subject and
# columns for proficiency, LL, and prime condition.
# 
# 4) Repeat step 1-3 about 200 times, each time appending the the new rows to
# the data.frame/table from step 3. 
# 
# 5) Make the same plot (x = profiency, y = LL, color = priming condition)
# as discussed before. This is easy and has the nice side benefit that each
# non-native subject now forms a distribution (with CIs, yay!) of LLs.
# 
# The simplifying assumption behind this is that we're assessing non-native
# subject's 'nativeness' (likelihood) while assuming that the sample of random
# differences among natives is sufficiently representative of the population.
# I think that's ok (but the CIs will also give you an idea how much of a
# non-native  subject's 'nativeness' depends on the random by-subject variances).

# If we so fancy, one can analyze the LLs with a gamm or glmm, but perhaps
# the visualization does the job?



# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Set up workspace --------------------------------------------------------
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

library(dplyr)
# library(lme4)
# library(tidyr)
library(ggplot2)
library(mgcv)  # GAMs and GAMMs (Wood 2006)
# library(itsadug)
# library(boot)  # for inv.logit()	
# library(lazyeval)  # lazy evaluation used in bysubj() function [summarise_]	
# library(effects)	
# library(xtable)	


## Load data files
d <- read.csv("data/data_gamms_baseline-doublecounted.csv",
              stringsAsFactors = FALSE)
head(d)

# divide into data from native speakers (NS) and L2ers
d_ns <- d %>% filter(Group == "NS")
d_ns$Subject <- factor(d_ns$Subject)  # drop unused factors for subject
d_l2 <- d %>% filter(Group == "L2")
d_l2$Subject <- factor(d_l2$Subject)  # drop unused factors for subject


# load native speaker GAMMs (created in "analysis/main-analyses.Rmd")
# gam_ns includes trial:condition interaction
load("analysis/gamms/gam_ns.rda")  
# gam_ns does not include trial:condition interaction
load("analysis/gamms/gam_ns_no_trialinter.rda")


# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Function to compute log-likelihood under native model  ------------------
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## APPROACH 1:
# LL is only computed under the full native model (with Condition:Trial 
# interaction)

# this function assigns the subject IDs from the natives randomly to the 
# subjects in "d_new" (the data from which we want to predict); if you do
# this on many iterations you're getting a distribution for the likelihood
# of the new data under the native model, while assuming that the random
# adjustments in natives captures well the randomness of the group you're
# predicting from (in this case, importantly, L2 speakers).

# Function
mypredict <- function(
  d_new = NULL,  # new data to which the predict function will be applied
  N = 20,  # number of iterations
  d_nat = d_ns,  # original df for the native speakers (needed to assign subject IDs)
  mygam = gam_ns,  # native speaker model from which we want to predict
  print_each_step = FALSE  # for use with myprint() function to understand function
) {
  
  # myprint function to print intermediate objects
  myprint <- function(x) {
    if (print_each_step) { 
      cat("\n"); print(paste("This is ", deparse(substitute(x)))); cat("\n")
      print(x)}}
  
  # Initiate data frame with the actual subjects for which values are predicted
  # NB: Subject needs to be the first grouping variable, so that order matches
  # the order of the step below where by-subject mean LLs are computed!
  pred <- d_new %>% group_by(Subject, Condition, ClozeScore) %>% summarise()
  myprint(head(pred))
  
  # Matrix that will contain the predicted values in each loop
  store_values <- matrix(nrow = length(unique(d_new$Subject)), ncol = N)
  myprint(store_values[1:7,])
  
  # Add column to keep track of the real subjects before assigning them random IDs
  d_new$TrueSubject <- d_new$Subject
  myprint(head(d_new))
  
  for (n in 1:N) {
    print(paste("iteration", n))
    
    # Override subject info by randomly assigning native subject IDs with repl.
    levels(d_new$Subject) <- sample(unique(d_nat$Subject), replace = TRUE,
                                    size = length(unique(d_new$Subject)))
    myprint(head(d_new))
    
    # predict participant data under native model (includes subject smooths)
    d_new$predicted <- predict.gam(mygam, newdata = d_new, type = "response")
    myprint(head(d_new))
    
    # Now log the probability of each observation (=trial) under the current
    # (native) model (with randomly assigned by-subject smooths), giving you
    # the log-likelihood (LL) of an observation under the native model:
    d_new$LL <- with(d_new, log(ifelse(Used == 1, predicted, 1 - predicted)))
    myprint(head(d_new))
    # and now average these log-probabilities by participant, to obtain the 
    # mean log-likelihoods (LL) of a participant's data under the native model
    mean_sbj_LL <- d_new %>% 
      group_by(TrueSubject) %>%
      summarise(LL = mean(LL))
    myprint(head(mean_sbj_LL))
    # put these values into the corresponding iteration column of store_values
    store_values[, n] <- mean_sbj_LL %>% pull(LL)
    myprint(store_values[1:7,])
  }
  
  # N random assignments lead to a distribution of mean LL by subject
  myConfint <- t(apply(store_values, 1, quantile, probs = c(.05, .5, .95)))
  myprint(myConfint[1:7,])
  
  # Join the original information with the estimates (5, 50 and 95 percentiles)
  myprint(head(pred))
  pred <- data.frame(pred, myConfint)
  myprint(head(pred))
  # give meaningful names
  names(pred)[4:6] <- paste("quant", c("05", "50", "95"), sep = "")
  myprint(head(pred))
  # add the number of iterations on which this is based
  pred$nbIterations <- N
  # good to go!
  pred
}

# Example that prints out all the intermediate steps to undertand function
(myex <- mypredict(d_new = d_l2, N = 2, print_each_step = TRUE)) %>% head(., 10)
rm(myex)


# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Log-likelihood of data sets under native model --------------------------
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

# run and time
ptm <- proc.time()
l2_under_natmodel_LL <- mypredict(d_new = d_l2, N = 50)
ns_under_natmodel_LL <- mypredict(d_new = d_ns, N = 50)
proc.time() - ptm

## combine native and non-native predictions
l2_under_natmodel_LL$Group <- "L2"
ns_under_natmodel_LL$Group <- "NS"

# save(l2_under_natmodel_LL, file = "analysis/gamms/l2_under_natmodel_LL.rda")
# save(ns_under_natmodel_LL, file = "analysis/gamms/ns_under_natmodel_LL.rda")

# load(file = "analysis/gamms/l2_under_natmodel_LL.rda")
# load(file = "analysis/gamms/ns_under_natmodel_LL.rda")


# predict the actual native speaker data under the native model without
# reassigning the subject IDs! (This should yield the highest log-likelihood)
d_ns$predicted <- predict.gam(gam_ns, newdata = d_ns, type = "response")
d_ns$LL <- with(d_ns, log(ifelse(Used == 1, predicted, 1 - predicted)))
# Store as dataframe with same shape as the two above
ns_actual_under_natmodel_LL <- d_ns %>%
  group_by(Subject, Condition, ClozeScore) %>% 
  summarise(quant50 = mean(LL)) %>% 
  mutate(quant05 = NA, quant95 = NA, Group = "ActualNS") %>%
  select(Subject:ClozeScore, quant05, quant50, quant95:Group)


# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Visualize log-likelihood ------------------------------------------------
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## L2ers

# L2 data sorted by Proficiency (Cloze score)
l2_under_natmodel_LL %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = Condition)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ylab("Log-likelihood of data\n(by-subject means)")

# With confidence intervals
l2_under_natmodel_LL %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = Condition,
             ymin = quant05, ymax = quant95)) +
  geom_point(position = position_dodge(width=0.5)) +
  geom_errorbar(width=0, position=position_dodge(width=0.5)) +
  geom_smooth(method = "lm")


## Native speakers

# Native speakers with randomly assigned subject numbers
ns_under_natmodel_LL %>%
  ggplot(aes(x = "NULL", y = quant50, colour = Condition)) +
  geom_boxplot()


# Combined predictions
combined_preds_LL <- rbind(l2_under_natmodel_LL, ns_under_natmodel_LL,
                        data.frame(ns_actual_under_natmodel_LL))

combined_preds_LL %>%
  ggplot(aes(x = Condition, y = quant50, colour = Group)) +
  geom_boxplot() +
  ylab("Log-likelihood of data\n(by-subject means)")




# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# Log-likelihood of data sets under native models (with vs without interaction)
# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

## APPROACH 2:
# LL is computed once for the full native model (with Condition:Trial
# interaction) and once for the *relevant* null model (without the interaction)
# -- it is the difference in LLs between those two models that we plot.

# This suggestion is explained and discussed in email correspondece with TFJ
# (Jaeger, Florian <fjaeger@UR.Rochester.edu>, Re: testing for interactions in
# GAMs, ons 2018-09-26 20:07 -- this email includes some discussion points)


source("analysis/functions/data-LL_under_native_model.R")

mycompar <- mypredict2(N = 250, d_ns, d_l2, mygam_basel = gam_ns,
                       mygam_alter = gam_ns_no_trialinter)

mycompar$VbType_Cond <- factor(mycompar$VbType_Cond, 
                               levels = c("P_V.Path", "P_V.Baseline",
                                          "M_V.Baseline", "M_V.Manner"))

# Compare L2/NS broken down by condition
mycompar %>%
  ggplot(aes(x = Condition, y = quant50, colour = Group)) +
  geom_boxplot() +
  ylab("Log-likelihood of data\n(by-subject means)")

# Compare L2/NS broken down by VbType_Cond (more meaningful given the model)
mycompar %>%
  ggplot(aes(x = VbType_Cond, y = quant50, colour = Group)) +
  geom_boxplot() +
  ylab("Log-likelihood of data\n(by-subject means)")

## L2ers only

# L2 data sorted by Proficiency (Cloze score)
mycompar %>%
  filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = Condition)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ylab("Log-likelihood of data\n(by-subject means)")

# L2 data sorted by Proficiency -- broken down by VbType_Cond 
mycompar %>%
  filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = VbType_Cond)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ylab("Log-likelihood of data\n(by-subject means)")

# no confidence bands
mycompar %>%
  filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = VbType_Cond)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ylab("Log-likelihood of data\n(by-subject means)")

# L2 data sorted by Proficiency with confidence intervals per subject
# -- note many of them are weird in that they only have one tail!
mycompar %>%
  filter(Group == "L2") %>%
  ggplot(aes(x = ClozeScore, y = quant50, colour = VbType_Cond,
             ymin = quant05, ymax = quant95)) +
  geom_point(position = position_dodge(width=0.5)) +
  geom_errorbar(width=0, position=position_dodge(width=0.5)) +
  geom_smooth(method = "lm", alpha = .25) +
  ylab("Log-likelihood of data\n(by-subject means)")
