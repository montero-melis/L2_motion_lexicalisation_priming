---
title: 'Main analyses: adaptation patterns in L2ers vs L1ers'
author: '[Guillermo Montero-Melis](http://www.biling.su.se/montero_melis_guillermo)'
date: '`r as.character(format(Sys.Date(), format="%d/%m/%Y"))`'
output:
  html_document:
    depth: 2
    number_sections: yes
    theme: default
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
  word_document:
    toc: yes
---


Intro
=====

After skyping on 30 July, we decided to streamline the analyses and make
them more consistent across the whole paper.

The main points we took up were:

- Adhere to the same type of analysis approach throughout: use an indicator
variable (Manner vs Path) and a Condition factor (Primed vs baseline)-
- Use GAMM and visualizations when reporting the main results for Questions 
1--3
- Be clear that to the best of our knowledge the GAMM implementation we use
does not allow for testing interactions (see, e.g.,
[here](http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm))
- Report therefore interaction effects using GLMMs while explaining the limitations of such
an analysis: 
First, the trends in the data are not linear (in log-odds space), as
shown in GAMMs, yet this is an assumption in GLMM.
Second, We will be testing up to 4-way interactions with a between-subject design,
so power to detect this effect will be low. 
- Run a GLMM for each of the GAMMs in a systematic fashion.
- In particular, for Q3, I have run a GLMM that allows us to compare adaptation
among the following groups: L2 low proficiency vs native speakers, and L2 high
proficiency vs native speakers. 
We hypothesized no difference between the high L2 proficiency group and natives,
but a significant difference between the low proficiency group and natives.
We hypothesize no difference between L2 high and natives, but a significant
difference between low profic and natives.

**Question to TFJ**: 
Would it make sense in our case to use Bayes Factors? Would we gain anything?


Set up workspace
================

##  Load libraries and functions

Libraries:

```{r, message=TRUE}
library(dplyr)
library(lme4)
library(tidyr)
library(ggplot2)
library(mgcv)  # GAMs and GAMMs (Wood 2006)
library(itsadug)
# library(boot)  # for inv.logit()	
library(knitr)  # for kable()
# library(lazyeval)  # lazy evaluation used in bysubj() function [summarise_]	
# library(effects)	
# library(xtable)	
```


Functions:

```{r, message=TRUE}
## Source somewhat more complex functions	

# # source functions to compute collinearity diagnostics	
# source("functions/kappa_mer_fnc.R")	
# source("functions/vif_mer_fnc.R")	

# Function that plots mixed model-estimates in logit space from baseline
# conditions, including speaker estimates
source("functions/plot_glmm_fnc.R")

# # source multiplot function	
# source("functions/multiplot_fnc.R")	

# Function used to load models if they have already been saved,
# rather than fitting them anew each time the script is called
source("functions/load_or_fit_fnc.R")

# Two functions to a) plot the differences between NS and L2 speakers from GAMMs,
# and b) plot the effects by L2 speakers' proficiency from GAMMs
source("functions/plot_gams_fnc.R")
```

```{r}
## Simpler convenience functions:	

# center predictors in a regression
source("functions/myCenter.R")

# print deviance explained as percentage and rounded to 1 decimal
dev_expl <- function(fm) {
  devi <- summary(fm)$dev.expl
  round(100 * devi, 1)
}

# create a neat table of the summary of fixed effects of a mixed model	
glmm_tb <- function(fm) {	
  m <- round(summary(fm)$coefficients, 3)	
  tb <- as.data.frame(m)	
  names(tb) <- c("Estimate", "SE", "z-value", "p-value")	
  kable(tb)	
}	
```


```{r, include=FALSE}
## Specify some global parameters

# adjust figure heght/width when not going with default (espec. for 2x2 plots)
myfighe_NS_L2 <- 6
myfighe_L2_prof <- 6
myfigwi <- 7
```


## Load and process data	

Load annotated description data for production task:

```{r}
# The data is created in the script 'processing/compute_dependent_measures.R'
# There is the normal and the liberally coded version (see script for difference).	
# Here I use the normal coding.	

# load	
d <- read.csv('../data/data_DVs.csv', fileEncoding = 'UTF-8', stringsAsFactors = TRUE)	
# simplify somewhat	
d <- d %>%	
  dplyr::select(Subject:VideoName, P_V, M_V) %>%	
  rename(Trial = VideoTrial)	
# Rename "Control" condition to "Baseline"	
levels(d$Condition)[levels(d$Condition) == "Control"] <- "Baseline"	
# Centre Trial	
d$cTrial <- d$Trial - mean(d$Trial)	
# check out
head(d)
str(d)
```

Add L2 proficiency scores:

```{r}
# participant data
ppts <- read.csv("../data/participants.csv", fileEncoding = "UTF-8",
                 stringsAsFactors = TRUE)
# No audio data recorded for Subject 14 (L2) due to experimental error; exclude
ppts <- ppts[ppts$Subject != 14, ]
ppts$Subject <- factor(ppts$Subject)

# transform ClozeScore to z-score (as.vector prevents it from becoming a matrix)
ppts$zClozeScore <- as.vector(scale(ppts$ClozeScore))
# center ClozeScore but not scaling (as.vector prevents it from becoming a matrix)
ppts$cClozeScore <- as.vector(scale(ppts$ClozeScore, scale = FALSE))

# Turn L2 proficiency into a categorical (ordered) variable.
# Do this by assigning cloze scores <= 40th percentile to "low",
# scores >= 60th percentile to "high", and the rest to "medium", 
# which shall not be analyzed in the group comparison followign up on Question 3
cutoff_prof <- quantile(ppts$ClozeScore, c(.4, .6), na.rm = TRUE)
ppts$Profic_categ <- with(ppts,
                          ifelse(ClozeScore <= cutoff_prof[1], "low prof",
                                 ifelse(ClozeScore >= cutoff_prof[2], "high prof", 
                                        "medium prof")))
# native speakers
ppts$Profic_categ[with(ppts, is.na(Profic_categ) & Group == "NS")] <- "native"
# Leads to the following nuber of observations:
table(ppts$Profic_categ)
# Note unbalance: high prof group is not equally represented in the three conditions
addmargins(with(ppts, table(Profic_categ, Condition)))
# add speakers' clozescore and derived measures to d:
d <- left_join(d, ppts %>% dplyr::select(Subject, ClozeScore, zClozeScore,
                                         cClozeScore, Profic_categ))
# NB: Subject NS_1 is in dataframe "d" but missing from df "ppts", while Subject
# NS_202 is in "ppts" but missing from "d". Both were in the baseline condition.
# Subject needs to be a factor
d$Subject <- factor(d$Subject)
# check out
head(d)
str(d)
```


Reshape data to long format and some further processing:

```{r}
# DOUBLE COUNTING APPROACH
# Convert data to long format:	
d_long <- gather(d, VerbType, Used, P_V:M_V)

# Combine VerbType (Path/Manner) and Condition (baseline/primed) into a single
# factor -- this is needed for the GAMMs
d_long$VbType_Cond <- with(d_long, interaction(VerbType, Condition))	

# For the subjects  to be properly fitted as random terms in the regression 
# models, we have to "pretend" that a baseline subject is two different subjects,
# one for the comparison to path-primed, the other to manner-primed participants;	
# this may not be ideal statistically (we'll assume independence where there
# isn't), but not doing this would mess up the estimation of random effects.	
d_long$Subject <- with(d_long, interaction(Subject, VerbType))	

## Subset data for model fitting:
# We are removing observations that	
# correspond to path verbs produced in the manner-primed condition or to manner	
# verbs produced in the path-primed condition)	
d_mod <- d_long %>% filter(! VbType_Cond %in% c("P_V.Manner", "M_V.Path"))
rm(d_long)  # remove to avoid using it by mistake

# drop unused factor levels and order levels correctly
d_mod$VbType_Cond <- factor(d_mod$VbType_Cond, 
                            levels = c("P_V.Baseline", "P_V.Path", "M_V.Baseline",
                                       "M_V.Manner"))
# drop unused factors for subject (important for random effects estimation)
d_mod$Subject <- factor(d_mod$Subject)
# Condition recoded as a binary factor (Path/Manner become "Primed")
d_mod$Condition_bin <- d_mod$Condition
levels(d_mod$Condition_bin)[levels(d_mod$Condition_bin) %in% c("Path", "Manner")] <- "Primed"	
table(d_mod$Condition_bin)  # roughly balanced (remember Baseline ppts are "doubled")
```


Coding scheme for factors:

```{r}
# Keep a dummy coded version of each factor:
d_mod$Group_dummy <- factor(d_mod$Group, levels = c("NS", "L2"))
contrasts(d_mod$Group_dummy)
d_mod$VerbType_dummy <- factor(d_mod$VerbType, levels = c("P_V", "M_V"))
contrasts(d_mod$VerbType_dummy)
d_mod$Condition_bin_dummy <- factor(d_mod$Condition_bin)
contrasts(d_mod$Condition_bin_dummy)
# define factor coding scheme (contrast coding)
# group
contrasts(d_mod$Group) <- contr.sum(2)
colnames(contrasts(d_mod$Group)) <- "L2_vs_NS"
contrasts(d_mod$Group)
# Verb type
d_mod$VerbType <- factor(d_mod$VerbType)
contrasts(d_mod$VerbType) <- contr.sum(2)
colnames(contrasts(d_mod$VerbType)) <- "M_vs_P"
contrasts(d_mod$VerbType)
# Condition_bin contrast coding	
contrasts(d_mod$Condition_bin) <- - contr.sum(2)
colnames(contrasts(d_mod$Condition_bin)) <- "Primed_vs_Baseline"	
contrasts(d_mod$Condition_bin)	
```

Show data frame

```{r}
head(d_mod)
str(d_mod)
```

```{r}
# Save this data set to disk for use with other scripts
d_mod %>% 
  dplyr::select(Subject:ClozeScore, VerbType:Condition_bin) %>%
  write.csv(file = "../data/data_gamms_baseline-doublecounted.csv",
            row.names = FALSE, fileEncoding = "UTF-8")
```




Baseline condition
==================

We compare overall use of path and manner verbs in the baseline condition and
for the two groups (L2ers, natives).
The predictors are:

- *Verb type*: Indicator variable with two levels (1 = manner, -1 = path)
- *Group*: factor with two levels (1 = L2ers, -1 = native speakers)


## Data and processing

Subset data to use only participants in baseline:

```{r}
# Subset data to use only baseline condition
d_basel <- d_mod %>% filter(Condition == "Baseline")
with(d_basel, table(Group, VerbType))
```


Recode subject identifiers:

```{r}
# In the baseline condition, we can model each subject as providing two 
# observations per trial: whether they produced a path verb and whether they
# produced a manner verb. The VerbType variable indicates that.
# Recode therefore individual subjects reverting the "doubling" of baseline
# subjects
# Before:
head(unique(d_basel[, c("Subject", "Group")]), 3)
d_basel$Subject <- sub("\\..*", "", d_basel$Subject)
# After:
head(unique(d_basel[, c("Subject", "Group")]), 3)
d_basel$Subject <- factor(d_basel$Subject)  # factor
```


Coding scheme:

```{r}
# verify coding scheme for factors
contrasts(d_basel$Group)  # group
contrasts(d_basel$VerbType)  # verb type
```


## Descriptives

```{r}
# Descriptive data for all analysed conditions
# table (will need to be appropriately formatted in report)
tb_descriptive_basel <- d_basel %>%
  group_by(VerbType, Group) %>%
  summarise(Occurrences = sum(Used),
            TotalN = n(),
            Percentage = round(100 * sum(Used) / n(), 1))
kable(tb_descriptive_basel)
```


## GLMM


```{r, echo = TRUE}
# load model or fit
glmm_basel.expr <- "glmer(Used ~ VerbType * Group + 
(1 + VerbType | Subject) + (1 + VerbType * Group | VideoName),
data = d_basel, family = 'binomial',
control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
load_or_fit("glmm_basel", glmm_basel.expr)
# output table
glmm_tb(glmm_basel)
```

Model summary

```{r}
summary(glmm_basel)
```


Plot the results:

```{r}
# the function is defined in analysis/functions/plot_glmm_fnc.R
plot_basel(glmm_basel, d_basel, nb_sims = 50)  # Adjust nb_sims (TO DO)
```




Question 1: Trial-by-trial adaptation of native speakers 
========================================================

Q1:

*Will native speakers show an inverse preference effect in their adaptation to the lexicalization patterns in the input? Theories that attribute adaptation to error-based or related learning mechanisms, predict this to be the case. If so, natives should adapt more strongly to manner verbs (uncommon in Spanish) than to path verbs (preferred in Spanish). This finding would also provide a conceptual replication of previous work on inverse preference effects in L1 syntactic priming (see references in the introduction), but for LEXICAL ENCODING and on another L1, Spanish.*

## GAMM analysis

### Data and processing

```{r}
## Subset data:
# Data for analysis of Native speakers
d_ns <- d_mod %>% filter(Group == "NS")
# drop unused factors for subject (I think this is important for gam fitting)
d_ns$Subject <- factor(d_ns$Subject)

# note log-odds of path verbs in baseline condition becomes the reference level
contrasts(d_ns$VbType_Cond)
```


### GAMM fitting

Previous models (not reported here) showed that random *intercepts* by items
made sense, but not random slopes. We add the former but not the latter.

Thus, the model is specified as:

`DV ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're')`

Predictors are:

- `VbType_Cond`: VerbType-Condition interaction as a fixed effect. The four levels
of this variable decompose into two crossed factors:
  - `VerbType`: Indicator variable that defines what is being measured by the DV,
  either the occurrence of path verbs or of manner verbs
  - `Condition`: Primed vs baseline
- `s(Trial, by = VbType_Cond)`: A smooth function of `Trial` allowing the function to differ for each level of Group-Condition (thin plate regression splines, the default)
- `s(Trial, Subject, bs = 'fs')`: Factor smooths for `Subject` to capture non-linear random effects of speakers
- `s(VideoName, bs = 're')`: Random intercepts by items (i.e., `VideoName`)


```{r gam_ns}
# the expression that is passed to load_or_fit()
gam_ns.expr <- "bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) +
                    s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're'),
                  data = d_ns,
                  family = 'binomial')"
# load model or fit
load_or_fit("gam_ns", gam_ns.expr)
```


```{r gam_ns_no_interaction}
# GAM without the trial:VbType_Cond interaction (to use in other scripts) 
# the expression that is passed to load_or_fit()
gam_ns_no_trialinter.expr <- "bam(Used ~ VbType_Cond + s(Trial) +
                    s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're'),
                  data = d_ns,
                  family = 'binomial')"
# load model or fit
load_or_fit("gam_ns_no_trialinter", gam_ns_no_trialinter.expr)
```


### Output and summary plots

Summary of the model:

```{r}
summary(gam_ns)
```


Summary using gamtabs:

(NB: Copy function from `supplementary-info.Rmd` if I want to use the function.)


```{r, results = "asis"}
# gam_tb(gam_ns)
```


Significance of the different terms in the model:

```{r}
anova(gam_ns)
```


Plot model estimates by condition, random smooth adjustments by speakers and QQ-plot of random by-item intercepts:

```{r, results = 'hide'}
## plot
plot_smooth(gam_ns, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
```


```{r}
# show by-speaker random smooths and by-item random intercepts
par(mfrow = c(1, 2))
plot(gam_ns, select = 5)
plot(gam_ns, select = 6)
```


### Result plots

Plot differences between conditions (model estimates):

```{r, fig.height = myfighe_NS_L2, fig.width = myfigwi, echo = TRUE, results = 'hide'}
plot_gam_main(gam_ns, "NS")  # choose this on Linux machine
# on my old windows computer:
# plot_gam_main(gam_ns, "NS", mark.diff = FALSE)  # use of mark.diff is a hack to
# avoid an error that will stop the whole thing when I compile it on my work pc
```


```{r}
# # save to disk for thesis chapter
# tiff(file = "figures/gam_natives.tiff", width = 5, height = 5.2, units = "in", pointsize = 10, res = 800)
# plot_gam_main(gam_ns, "NS")
# dev.off()
```



## GAMM analysis -- without double counting

We repeat the analysis, only we don't double count participants in the
baseline condition as above. Instead, we use a 2-fold-cross-validation of
sorts:

1) Randomly assign half of the baseline participants to "path verb" condition
(`VerbType` = `P_V`) and the other half to the manner verb condition.
2) Run the same GAMM as before
3) Invert the assignment in 1) and procede to 2).
4) Evaluate if the results are stable.

This is achieved using the `load_or_fit_2foldx` function (see script
`analysis/functions/load_or_fit_fnc.R`).


### GAMM fitting



```{r}
# check the source code of the function to understand how it works
load_or_fit_2foldx("gam_ns", gam_ns.expr, myrandseed = 530)
load_or_fit_2foldx("gam_ns", gam_ns.expr, myrandseed = 330)
```


### Output and summary plots

Summary of the model:

```{r}
summary(gam_ns_2foldx_530_fold1)
summary(gam_ns_2foldx_530_fold2)
summary(gam_ns_2foldx_330_fold1)
summary(gam_ns_2foldx_330_fold2)
```


Summary using gamtabs:

(NB: Copy function from `supplementary-info.Rmd` if I want to use the function.)


```{r, results = "asis"}
# gam_tb(gam_ns_2foldx_530_fold1)
```


Significance of the different terms in the model:

```{r}
# anova(gam_ns_2foldx_530_fold1)
```


Plot model estimates by condition, random smooth adjustments by speakers and QQ-plot of random by-item intercepts:

```{r, results = 'hide'}
## plot
plot_smooth(gam_ns_2foldx_530_fold1, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
plot_smooth(gam_ns_2foldx_530_fold2, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
plot_smooth(gam_ns_2foldx_330_fold1, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
plot_smooth(gam_ns_2foldx_330_fold2, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
```


```{r}
# show by-speaker random smooths and by-item random intercepts
# par(mfrow = c(1, 2))
# plot(gam_ns, select = 5)
# plot(gam_ns, select = 6)
```


### Result plots

Plot differences between conditions (model estimates):

```{r, fig.height = myfighe_NS_L2, fig.width = myfigwi, echo = TRUE, results = 'hide'}
plot_gam_main(gam_ns_2foldx_530_fold1, "NS")  # choose this on Linux machine
plot_gam_main(gam_ns_2foldx_530_fold2, "NS")  # choose this on Linux machine
plot_gam_main(gam_ns_2foldx_330_fold1, "NS")  # choose this on Linux machine
plot_gam_main(gam_ns_2foldx_330_fold2, "NS")  # choose this on Linux machine
# on my old windows computer:
# plot_gam_main(gam_ns, "NS", mark.diff = FALSE)  # use of mark.diff is a hack to
# avoid an error that will stop the whole thing when I compile it on my work pc
```


```{r}
# # save to disk for thesis chapter
# tiff(file = "figures/gam_natives.tiff", width = 5, height = 5.2, units = "in", pointsize = 10, res = 800)
# plot_gam_main(gam_ns, "NS")
# dev.off()
```




## GLMM analysis

### Rationale

Based on the GAMM analysis, we can see that for native speakers there was a
significant adaptation effect for Manner, but not for Path verbs.
However, we cannot conclude from different patterns, that they are
significantly different. 
Because this type of interaction analysis in a factorial design is 
difficult to implement in the GAM framework we are using (see, e.g.,
[here](http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm)),
we carry out a follow-up mixed logistic regression analysis to address this
interaction. 


### GLMM fitting

Verify factors are contrast coded and `cTrial` is centred:

```{r}
# Verify factors are contrast coded:
contrasts(d_ns$Condition_bin)
contrasts(d_ns$VerbType)
d_ns$cTrial <- d_ns$cTrial - mean(d_ns$cTrial)  # recentre
mean(d_ns$cTrial)
```


In these and all the following GLMMs, we try to stay conceptually close to the
random effects structure used in the GAMMs. This means we will generally
try to fit a model with random by-item and by-subject intercepts, as well as
a random by-subject slope for `cTrial` (corresponding to the smooth term
`s(Trial, Subject, bs = 'fs')` in the GAMMs).

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_ns.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_ns, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_ns", glmm_ns.expr)
```


```{r, echo = FALSE}
# # MINIMAL random effects, only by-subject and by-item intercepts
# # expression to be passed to the load_or_fit function:
# glmm_ns_min.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 | Subject) + (1 | VideoName),
#                        data = d_ns, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_ns_min", glmm_ns_min.expr)
```


```{r, echo = FALSE}
# # MAXIMAL random effects -- fails to converge, with error message:
# # "unable to evaluate scaled gradientModel failed to converge: degenerate
# # Hessian with 7 negative eigenvalues"
# # expression to be passed to the load_or_fit function:
# glmm_ns_max.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 + cTrial | Subject) + (1 + Condition_bin * VerbType | VideoName),
#                        data = d_ns, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_ns_max", glmm_ns_max.expr)
```

```{r}
summary(glmm_ns)
```


### Collinearity issue

Florian notes (email 2018-08-17) that adding the random by-subject slope for
`cTrial` to the REs increases the correlaton between some of the fixed effects.
Some of these correlations are now > .5, whereas they were mostly <= .1 in the
random-intercepts-only model (e.g., correlation between intercept and `cTrial`
or between the interaction `Condition_binPrimed_vs_Baseline:cTrial` and
the main effect of `Condition_binPrimed_vs_Baseline`, and there's one more).

Florian wonders:
"I don't understand why trial isn't entirely orthogonal to the other
factors (which are *between* subjects) and why this only emerges when the
random slope is involved. could there be some coding issue, or sth like some
subjects only have some trials?"

Guillermo's comments:

`cTrial` is appropriately centred and the other two factors are contrast coded.
It is not really the case that some subjects only have some trials. There are
few missing observations for subject-trial combinations:

```{r}
sum(with(d_ns, table(Subject, Trial)) != 1)
```


Let us look at the balance between observations in the two factors:

```{r}
with(d_ns, table(VerbType, Condition_bin))
```

It is not a huge imbalance, but we can centre the two factors and re-fit the
model:

```{r}
# invert sign to keep the original interpretation (Manner vs Path)
d_ns$cVerbType <- - myCenter(d_ns$VerbType)
d_ns$cCondition_bin <- myCenter(d_ns$Condition_bin)
head(d_ns, 3)
```


Fit the model with the slight change in coding:

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_ns_centred.expr <- "glmer(Used ~ cCondition_bin * cVerbType * cTrial +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_ns, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_ns_centred", glmm_ns_centred.expr)
```

```{r}
summary(glmm_ns_centred)
```

Nothing has changed with respect to collinearity, so coding of the factors
did not seem to be the issue.


### Embedding under `VerbType`

Following Florian's suggestion (2018-08-19), we fit a nested model so that
the effect of priming and its interactions are nested under condition:

```{r}
# Expression to be passed to the load_or_fit function:
glmm_ns_embed.expr <- "glmer(Used ~ VerbType / (Condition_bin * cTrial) +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_ns, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_ns_embed", glmm_ns_embed.expr)
```

```{r}
summary(glmm_ns_embed)
```


### Model interpretation (native speakers)


Quick and dirty plot

```{r}
glmm_ns_predicted <- data.frame(d_ns, Predicted = predict(glmm_ns))
glmm_ns_predicted %>%
  group_by(Condition_bin, VerbType, Trial) %>%
  summarise(Y = mean(Predicted)) %>%
  ggplot(aes(x = Trial, y = Y, shape = Condition_bin, colour = VerbType)) +
  geom_point() +
  geom_line()
```


The interpretation of the estimates for the main effects is as follows (following
the model output of `glmm_ns`, whose RE structure is similar to the GAMM):

- `Condition_binPrimed_vs_Baseline`: On average, participants are more likely
to use a certain type of verb (path or manner) if there are primed with that
verb type than if they are not.
- `VerbTypeM_vs_P`: Path verbs were more likely to be used than Manner verbs
- `cTrial`: Trial does not on average increase the likelihood of producing a
target verb.
- `Condition_binPrimed_vs_Baseline:VerbTypeM_vs_P`: The effect of priming
did not differ across verb types
- `Condition_binPrimed_vs_Baseline:cTrial`: When primed, participants tended
to increase the use of the primed verb more than in the baseline condition.
- `VerbTypeM_vs_P:cTrial`: Production of path verbs tended to increase more
over the course of the experiment than production of manner verbs.
- `Condition_binPrimed_vs_Baseline:VerbTypeM_vs_P:cTrial`: This 3-way 
interaction is the one that directly tests whether the adaptation effect
over the experiment was greater for manner than for path verbs. The 
estimate for this effect is not significantly different from zero, so the
results do not support this prediction.


Question 2: Trial-by-trial adaptation of L2 learners
========================================================

Q2:

*Our second question is whether L2 learners adapt to recent input as a function of both their L1 and L2 experience or of their L2 experience only. If learners’ expectations about the L2 input are mediated by their L1 experi¬ence, this should bias them towards expecting manner verbs more, and path verbs less, than native Spanish speakers. In this case, learners should—in comparison to natives—adapt more to path verbs and less to manner verbs. If, on the other hand, learners’ expectations are only a function of their L2 experience, then learners should adapt qualitatively like native speakers: more strongly to manner verbs than to path verbs.*


## GAMM analysis

### Data and processing

```{r}
## Subset data:
# Data for analysis of Native speakers (note we are removing observations that
# correspond to path verbs produced in the manner-primed condition or to manner
# verbs produced in the path-primed condition)
d_l2 <- d_mod %>% filter(Group == "L2")
# drop unused factors for subject (I think this is important for gam fitting)
d_l2$Subject <- factor(d_l2$Subject)

# note log-odds of path verbs in baseline condition becomes the reference level
contrasts(d_l2$VbType_Cond)
```


### GAMM fitting

Previous models (not reported here) showed that random *intercepts* by items
made sense, but not random slopes. We add the former but not the latter.

Thus, the model is specified as:

`DV ~ VbType_Cond + s(Trial, by = VbType_Cond) + s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're')`

Predictors are:

- `VbType_Cond`: VerbType-Condition interaction as a fixed effect. The four levels
of this variable decompose into two crossed factors:
  - `VerbType`: Indicator variable that defines what is being measured by the DV,
  either the occurrence of path verbs or of manner verbs
  - `Condition`: Primed vs baseline
- `s(Trial, by = VbType_Cond)`: A smooth function of `Trial` allowing the function to differ for each level of Group-Condition (thin plate regression splines, the default)
- `s(Trial, Subject, bs = 'fs')`: Factor smooths for `Subject` to capture non-linear random effects of speakers
- `s(VideoName, bs = 're')`: Random intercepts by items (i.e., `VideoName`)


```{r gam_l2}
# the expression that is passed to load_or_fit()
gam_l2.expr <- "bam(Used ~ VbType_Cond + s(Trial, by = VbType_Cond) +
                    s(Trial, Subject, bs = 'fs') + s(VideoName, bs = 're'),
                  data = d_l2,
                  family = 'binomial')"
# load model or fit
load_or_fit("gam_l2", gam_l2.expr)
```


### Output and summary plots

Summary of the model:

```{r}
summary(gam_l2)
```


Summary using gamtabs:

(NB: Copy function from `supplementary-info.Rmd` if I want to use the function.)


```{r, results = "asis"}
# gam_tb(gam_l2)
```


Significance of the different terms in the model:

```{r}
anova(gam_l2)
```


Plot model estimates by condition, random smooth adjustments by speakers and QQ-plot of random by-item intercepts:

```{r, results = 'hide'}
## plot
plot_smooth(gam_l2, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
```


```{r}
# show by-speaker random smooths and by-item random intercepts
par(mfrow = c(1, 2))
plot(gam_l2, select = 5)
plot(gam_l2, select = 6)
```


### Result plots

Plot differences between conditions (model estimates):

```{r, fig.height = myfighe_NS_L2, fig.width = myfigwi, echo = FALSE, results = 'hide'}
plot_gam_main(gam_l2, "L2")  # choose this on Linux machine
# on my old windows computer:
# plot_gam_main(gam_l2, "L2", mark.diff = FALSE)  # use of mark.diff is a hack to
# avoid an error that will stop the whole thing when I compile it on my work pc
```


```{r}
# # save to disk for thesis chapter
# tiff(file = "figures/gam_natives.tiff", width = 5, height = 5.2, units = "in", pointsize = 10, res = 800)
# plot_gam_main(gam_l2, "L2")
# dev.off()
```


## GLMM analysis

### Rationale

The rationale is the same as for native speakers.
The difference is that the patterns are less linear for L2ers than for
natives. We therefore do two analyses:

1) Using the data from all the trials;
2) Using only the data from the trials that are approximately linear (based
on visual inspection).


### GLMM fitting -- use data from all trials

Verify factors are contrast coded:

```{r}
# Verify factors are contrast coded:
contrasts(d_l2$Condition_bin)
contrasts(d_l2$VerbType)
```

GLMM with RE structure closest to the GAMM (see section 4.2.2):

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_l2.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_l2, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_l2", glmm_l2.expr)
```


```{r, echo = FALSE}
# # MINIMAL random effects, only by-subject and by-item intercepts
# # expression to be passed to the load_or_fit function:
# glmm_l2_min.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 | Subject) + (1 | VideoName),
#                        data = d_l2, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_l2_min", glmm_l2_min.expr)
```


```{r, echo = FALSE}
# # MAXIMAL random effects (does not converge)
# # expression to be passed to the load_or_fit function:
# glmm_l2_max.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 + cTrial | Subject) + (1 + Condition_bin * VerbType | VideoName),
#                        data = d_l2, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_l2_max", glmm_l2_max.expr)
```


```{r}
summary(glmm_l2)
```


### GLMM fitting -- use data that shows linear trend only

We run an analysis identical  to the one above, but using only the data from
the trials that show an approximately linear relation with the outcome variable
(based on visual inspection). This means we keep trials 1 through 13.

Subset data:

```{r}
d_l2_lin <- d_l2 %>% filter(Trial <= 13)
# recenter cTrial
d_l2_lin$cTrial <- d_l2_lin$Trial - mean(d_l2_lin$Trial) 
```

GLMM with RE structure closest to the GAMM (see section 4.2.2):

```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_l2_lin.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_l2_lin, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_l2_lin", glmm_l2_lin.expr)
```


```{r, echo = FALSE}
# # MINIMAL random effects, only by-subject and by-item intercepts
# # expression to be passed to the load_or_fit function:
# glmm_l2_lin_min.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 | Subject) + (1 | VideoName),
#                        data = d_l2_lin, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_l2_lin_min", glmm_l2_lin_min.expr)
```


```{r, echo = FALSE}
# # MAXIMAL random effects (does not converge)
# # Fails to converge with error message:
# # "unable to evaluate scaled gradientModel failed to converge: degenerate
# # Hessian with 1 negative eigenvalues"
# # expression to be passed to the load_or_fit function:
# glmm_l2_lin_max.expr <- "glmer(Used ~ Condition_bin * VerbType * cTrial +
#                          (1 + cTrial | Subject) + (1 + Condition_bin * VerbType | VideoName),
#                        data = d_l2_lin, family = 'binomial',
#                        control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_l2_lin_max", glmm_l2_lin_max.expr)
```


```{r}
summary(glmm_l2_lin)
```

### Embedding under `VerbType`

Following Florian's suggestion (2018-08-19), we fit a nested model so that
the effect of priming and its interactions are nested under condition:

```{r}
# Expression to be passed to the load_or_fit function:
glmm_l2_lin_embed.expr <- "glmer(Used ~ VerbType / (Condition_bin * cTrial) +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_l2_lin, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_l2_lin_embed", glmm_l2_lin_embed.expr)
```

```{r}
summary(glmm_l2_lin_embed)
```




### Model interpretation (L2ers)

Quick and dirty plot

```{r}
glmm_l2_lin_predicted <- data.frame(d_l2_lin, Predicted = predict(glmm_l2_lin))
glmm_l2_lin_predicted %>%
  group_by(Condition_bin, VerbType, Trial) %>%
  summarise(Y = mean(Predicted)) %>%
  ggplot(aes(x = Trial, y = Y, shape = Condition_bin, colour = VerbType)) +
  geom_point() +
  geom_line()
```

As was the case for the native speakers, the two GLMMs we fitted for L2 speakers
are qualitatively very similar.
But for L2 speakers, we fit two additional models for which we subset the data
selecting only data for trials 1 through 13, corresponding to the parts for
which the relation between trial and log-odds of producing a verb were 
approximately linear.
These four models do not differ substantially from each other.

Below, I interpret the main effects estimates for the model output of 
`glmm_l2_lin`, which is the one that selects only the linear part of
the data:

- `Condition_binPrimed_vs_Baseline`: On average, participants are more likely
to use a certain type of verb (path or manner) if there are primed with that
verb type than if they are not.
- `VerbTypeM_vs_P`: Path verbs were more likely to be used than Manner verbs
- `cTrial`: Trial did on average increase the likelihood of producing a
target verb (as opposed to native speakers where this effect wasn't significant).
- `Condition_binPrimed_vs_Baseline:VerbTypeM_vs_P`: The effect of priming
did not differ across verb types
- `Condition_binPrimed_vs_Baseline:cTrial`: When primed, participants tended
to increase the use of the primed verb more than in the baseline condition.
- `VerbTypeM_vs_P:cTrial`: Production of path verbs tended to increase more
over the course of the experiment than production of manner verbs.
- `Condition_binPrimed_vs_Baseline:VerbTypeM_vs_P:cTrial`: This 3-way 
interaction is the one that directly tests whether the adaptation effect
over the experiment was greater for path than for manner verbs. The 
estimate for this effect is not significantly different from zero, so the
results do not support this prediction.



Combined analysis for questions 2 and 3 (GLMM)
=======================================

This section tests whether there is a difference in adaptation at the group
level when comparing L1 and L2 speakers.
It is an analysis that compares the results from Questions 2 and 3,
and explores whether there is 4-way interaction suggesting that adaptation
patterns differ for natives and L2ers.


## Background

In the paper (draft6 from 180601), we write:

"Thus, learners differed from native speakers in the direction one would
expect if they were basing their L2 expectations on a mixture of their L1
and L2 experience. Even if learners did not show a statistically stronger
adaptation to path verbs than to manner verbs, they showed this numerical
tendency, whereas native speakers showed the opposite tendency (they adapted
to manner verbs but not to path verbs)."

Florian (comments on above draft) notes that this leads to the "classic 
interaction fallacy. We can’t conclude from different patterns, that they are
significantly different. This needs to be acknowleged, or better (required, 
I’d say) L1 vs. L2 should be included in the/a follow-up analysis."

Since this type of high-order interaction analysis in a factorial design is 
difficult to implement in the GAM framework (see, e.g.,
[here](http://grokbase.com/t/r/r-help/113qaadxt4/r-how-to-add-in-interaction-terms-in-gamm)),
we carry out a mixed logistic regression to ask this. 

Note, however, that this is not ideal because the trends in the data are not
linear (in log-odds space) *and* because we will be testing a 4-way interaction:
VerbType (Path/Manner) x PrimeCondition (baseline/primed) x
LanguageGroup (L1/L2) x Trial (1 through 32).
Power to detect this effect will be low.



## Factor explanation and coding

We analyze the data as a 2 x 2 x 2 design, with Trial as an additional (4th)
continuous predictor, in which all predictors interact:

- `VerbType`: Path vs Manner
- `Condition_bin`: Primed vs Baseline
- `LanguageGroup`: L2 vs NS
- `Trial`: 1-32 (but centred)

We will fit a model for the subset of the data that shows a linear trend
(see analysis of L2 data for Question 2).


```{r}
# Subset data
d_mod_lin <- d_mod %>% filter(Trial <= 13)
# recenter cTrial
d_mod_lin$cTrial <- d_mod_lin$Trial - mean(d_mod_lin$Trial) 
```


Verify factor coding and centering:

```{r}
# VerbType -- use contrast coding	
contrasts(d_mod_lin$VerbType)	
# (Language) Group -- use contrast coding	
contrasts(d_mod_lin$Group)	
# Condition - contrast coding	
contrasts(d_mod_lin$Condition_bin)
# Centred Trial	
head(d_mod_lin$cTrial)	
```


## GLMM fitting -- data that shows linear trend only

Random effects structure:

- By-item and by-subject intercepts
- `cTrial` as by-subject random slopes

```{r}
# expression to be passed to the load_or_fit function:
glmm_L1L2_lin.expr <- "glmer(Used ~ Condition_bin * VerbType * Group * cTrial +
                         (1 + cTrial | Subject) + (1 | VideoName),
                       data = d_mod_lin, family = 'binomial',
                       control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_L1L2_lin", glmm_L1L2_lin.expr)
```


## Interpretation

Quick and dirty plot

```{r}
glmm_L1L2_lin_predicted <- data.frame(d_mod_lin, Predicted = predict(glmm_L1L2_lin))
glmm_L1L2_lin_predicted %>%
  group_by(Condition_bin, VerbType, Group, Trial) %>%
  summarise(Y = mean(Predicted)) %>%
  ggplot(aes(x = Trial, y = Y, shape = Condition_bin, colour = VerbType)) +
  geom_point() +
  geom_line() +
  facet_grid(. ~ Group)
```

Model summary (see immediately below for a more readable output):

```{r}
summary(glmm_L1L2_lin)
```

TO DO (update pasted output!)

```
# Pasted from console for more readability:
> summary(glmm_L1L2_lin)

```



Note that **the 4-way interaction of interest is not even close to
signficance**.

Now, let's interpret each fixed-effects coefficient in the model
(it might help to look at Figures 3 and 4 of the manuscript):

**Intercept and main effects**

1. `Intercept`:The intercept is not very useful here, but it means that on average
there was slightly over 50% chance (but not significantly so) that path or manner
verbs were used in a target description when averaging across all predictor variables.
1. ***`ConditionPrimed_vs_Baseline`: Participants in a primed condition were 2 logits
more likely to use a path or manner verb than those in the baseline (unprimed)
condition.
1. ***`VerbTypeP_vs_M`: Path verbs were 2.1 logits more likely to be used than manner
verbs.
1. `GroupL2_vs_NS`: On average, natives and L2ers were equally likely to use
path or manner verbs.
1. **`cTrial`: On average, more path or manner verbs were used as the experiment
progressed.

**Two-way interactions**

1. `ConditionPrimed_vs_Baseline:VerbTypeP_vs_M`: No significant difference in
the priming effect of path and manner verbs with respect to baseline
(averaged over language groups).
2. *`ConditionPrimed_vs_Baseline:GroupL2_vs_NS`: There was a larger priming effect
for L2ers than for native speakers (averaged over verb types).
1. ***`VerbTypeP_vs_M:GroupL2_vs_NS`: L2ers produced more path verbs than manner verbs
compared to native speakers (averaged across primed and baseline conditions).
1. **`ConditionPrimed_vs_Baseline:cTrial`: The general increase of Path and Manner
verbs as the experiment progressed was greater in the primed than in the baseline
condition.
1. ***`VerbTypeP_vs_M:cTrial`: The increase in use of path verbs during the 
experiment was greater than the increase in use of manner verbs.
1. ***`GroupL2_vs_NS:cTrial`: The increase in use of path or manner verbs during the
experiment was greater for L2ers than for natives.

**Three-way interactions**

1. `ConditionPrimed_vs_Baseline:VerbTypeP_vs_M:GroupL2_vs_NS`: There was no
difference in how strongly L2ers and natives were primed by path vs manner
verbs (compared to baseline in each language group and for each verb type).
Such an effect would speak to the claim that the adaptation patterns
differed for the two language groups (the other relevant term being the 4-way
interaction reported below).
2. `ConditionPrimed_vs_Baseline:VerbTypeP_vs_M:cTrial`: No significant difference
in how much use of path or manner verbs increased in primed condition against
baseline as the experiment proceeded.
3. ***`ConditionPrimed_vs_Baseline:GroupL2_vs_NS:cTrial`: L2 speakers increased
their rate of prime verb use (path and manner averaged) verbs more rapidly
than native speakers as the experiment progressed (measured against their
respective baselines).
4. *`VerbTypeP_vs_M:GroupL2_vs_NS:cTrial`: The increase in use of path verbs
relative to manner verbs as the experiment progressed was less pronounced
in L2ers than in natives (seems to be driven by the fact that L2ers are more
strongly primed by manner verbs than natives).

**Four-way interaction**

- `ConditionPrimed_vs_Baseline:VerbTypeP_vs_M:GroupL2_vs_NS:cTrial`:
This was the effect of interest, for which there is no evidence in the data.
In the GAMs, we observed that manner adaptation was stronger than path adaptation
as the experiment went along for natives (which would correspond to a negative
coefficient for the `ConditionPrimed_vs_Baseline:VerbTypeP_vs_M:cTrial` term),
whereas the opposite seemed to be true for L2ers (corresponding to a negative
coefficient). What this 4-way interaction tells us is that there is no evidence
for this difference.

**Random effects**

Finally, note that the **random variance** induced by participants (modelled
as random intercepts and random slopes for `cTrial`, with SDs of 1.8 and 0.14,
respectively) was by far greater than that induced by items (SD of 0.09).
This may suggest that increasing model complexity might not make much difference
to the fixed-effect estimates, since all the random slopes that we have *not*
modelled can only be fitted by items (all predictors are between subjects except
for `cTrial`.)

NB: 

I don't know what the effect on the subject-variance estimate is of having
counted each participant in the baseline condition as two distinct participants,
one for their path verb production and another for their manner verb production.


## Conclusion

With the caveat that power for the effects we were looking for was probably
low, the conclusion is that there is no evidence for differences between
L2ers and natives regarding their patterns of adaptation to path and manner
verbs, at least when analyzed as a group.


Question 3: Effect of L2 proficiency on trial-by-trial adaptation
=================================================================


Q3:

*Our third and last question is whether L2 learners come to increasingly resemble native speakers in how they adapt to recent input as they become more proficient in their L2. If learners are indeed adapting to the input as a function of their expectations, and if their expectations become more attuned to the L2 (and rely less on the L1) with growing proficiency, we should see that learners progressively come to adapt more strongly to manner verbs and less strongly to path verbs  . This prediction does not follow from classical accounts of transfer in L2 processing/acquisition, and it would provide additional credence to the inverse frequency effects observed for native speakers in the analysis for our first question, and thus for theories that attribute adaptation to error-based or related learning mechanisms.*


## GAMM analysis

The difference with respect to our previous analysis (as reported in, e.g.,
`adaptation-L2_DRAFT6_180730.docx`) is that we fit a *single* model rather than
two separate ones for path and manner verbs as DVs.
In other words, we use the indicator variable approach we used in all previous
analyses.

We will thus predict the use of either path or manner verbs (depending
on the value of `VerbType`) as a function of:

- `Condition`: primed vs. baseline
- `Trial`: 1 through 32 (continuous variable)
- `ClozeScore`: A continuous measure of L2 proficiency
- Recall that the indicator variable `VerbType` is combined with `Condition`
to yield a 4-level factor, `VbType_Cond`.


### Data and processing

The data is the same as we used to address Question 2, only now we will use
the predictor `ClozeScore` to measure L2 proficiency.

First rows of the data set:

```{r}
head(d_l2)
```


### GAMM fitting

We start by fitting two models, one with and one without the interaction term
`te(Trial, ClozeScore, by = Condition)`
Using model comparison, we can see if this term significantly improves the model.

Model including 3-way interaction

```{r model_l2prof_with_interac}
# model with interaction
gam_l2prof.expr <- "bam(Used ~
    VbType_Cond +
    te(Trial, ClozeScore, by = VbType_Cond) +
    s(Trial, Subject, bs = 'fs') +
    s(VideoName, bs = 're'),
  data = d_l2,
  family = 'binomial')"
# load model or fit
load_or_fit("gam_l2prof", gam_l2prof.expr)
```

Model excluding the 3-way interaction

```{r model_l2prof_no_interac}
# model without the interaction
gam_l2prof_no3way.expr <- "bam(Used ~ 
                                 VbType_Cond + 
                                 s(Trial, by = VbType_Cond) + 
                                 s(ClozeScore, by = VbType_Cond) + 
                                 s(Trial, Subject, bs = 'fs') +
                                 s(VideoName, bs = 're'),
                               data = d_l2, family = 'binomial')"
# load model or fit
load_or_fit("gam_l2prof_no3way", gam_l2prof_no3way.expr)
```



The two models above differ in whether the effect of `Trial` is allowed
to interact with the effect of `ClozeScore` (L2 proficiency) at different
levels of `VbType_Cond`.
In the first model, the term `te(Trial, ClozeScore, by = VbType_Cond)` does
allow for this interaction.
In the second model, however, this interaction is not defined:

- The term `s(Trial, by = VbType_Cond)` allows the effect of Trial to be
different for the different levels of `VbType_Cond`
- The term `s(ClozeScore, by = VbType_Cond)` in turn allows the effect of
`ClozeScore` (L2 proficiency) to vary for the different levels of `VbType_Cond`
- However, the two effects can only be additive. Our prediction is precisely
that they are not, i.e. that the difference between baseline and each of the primed
conditions will depend on L2 proficiency.

### Model comparison

```{r}
# compare the models with itsadug::compareML()
# (see email correspondence with Florian J. Subject: "Our skype on L2 adaptation
# paper" (15 Feb 2017))
itsadug::compareML(gam_l2prof, gam_l2prof_no3way)
```

The additional complexity of the model *with* the interaction leads to a 
significantly better model.
We interpret this as supporting the idea that the adaptation effect to
Path and Manner changes with L2 proficiency.
In the remainder, we report the model with the interaction, and we use model
visualization to interpret this interaction.


### Output and summary plots

Summary of the model:

```{r}
summary(gam_l2prof)
```

Note that this model, which includes L2 proficiency, explains
`r dev_expl(gam_l2prof)`%
of the deviance in the data, whereas the model fit for Question 2, which
treated L2ers as a homogenous group, explained
`r dev_expl(gam_l2)`%
of the deviance.
This is a mere
`r dev_expl(gam_l2prof) - dev_expl(gam_l2)`%
in the amount of deviance explained -- not very impressive.




Summary using gamtabs:

(NB: Copy function from `supplementary-info.Rmd` if I want to use the function.)


```{r, results = "asis"}
# gam_tb(gam_l2prof)
```


Significance of the different terms in the model:

```{r}
anova(gam_l2prof)
```


Plot model estimates by condition, random smooth adjustments by speakers and QQ-plot of random by-item intercepts:

```{r, results = 'hide'}
# ## plot
plot_smooth(gam_l2prof, view = 'Trial', plot_all = 'VbType_Cond', rm.ranef=TRUE)
```

```{r, results = 'hide'}
## plot
plot_smooth(gam_l2prof, view = 'ClozeScore', plot_all = 'VbType_Cond', rm.ranef=TRUE)
```

```{r}
# # show by-speaker random smooths and by-item random intercepts
# par(mfrow = c(1, 2))
# plot(gam_l2prof, select = 5)
# plot(gam_l2prof, select = 6)
```


### Result plots

Plot differences between conditions (model estimates):

```{r, fig.height = 4, fig.width = 8, echo = TRUE, results = 'hide'}
plot_L2_profic_singlemodel(gam_l2prof, primed_cond = 'Path')
plot_L2_profic_singlemodel(gam_l2prof, primed_cond = 'Manner')
```


```{r}
# # save to disk for thesis chapter
# tiff(file = "figures/gam_natives.tiff", width = 5, height = 5.2, units = "in", pointsize = 10, res = 800)
# plot_gam_main(gam_l2, "L2")
# dev.off()
```


## GLMM analysis

### Rationale

Our primary analysis will use data from all the trials.
We are already losing power by dichotomizing L2 proficiency, and by removing
a number of participants in the mid-range of L2 proficiency.
So by keeping the data for all trials, we try not to further reduce power.

We divided L2 proficiency to categorize L2 speakers into
high/low L2 proficiency speakers.
What we did exactly was to categorize participants with proficiency scores
equal or below the 40th percentile as *low* proficiency (N = 24), those equal or
above the 60th percentile as *high* (N = 25), and exclude the rest of the 
participants (10 excluded).
This does unfortunately not lead to a balanced data set:

```{r}
addmargins(with(ppts, table(Profic_categ, Condition)))
```


Below are a density plot and two histograms (the latter only differing in their
binwidths) that show the distribution of participant scores on their L2
proficiency scores.
The two vertical lines show the value of the 40th and 60th percentiles.
Participants with scores below the 40th percentile were categorized as low
proficiency, those above the 60th percentile as high proficiency. Those
falling in between were dropped from the analyses.

```{r}
ggplot(ppts %>% filter(Profic_categ != "native"),
       aes(x = ClozeScore, fill = Condition)) +
  geom_density(alpha = .5) +
  geom_vline(xintercept = cutoff_prof) +
  annotate("text", x = 10, y = .055, label = "low\nproficiency") +
  annotate("text", x = 33, y = .055, label = "high\nproficiency")
```


```{r}
ggplot(ppts %>% filter(Profic_categ != "native"),
       aes(x = ClozeScore, fill = Condition)) +
  geom_histogram(binwidth = 3) +
  geom_vline(xintercept = cutoff_prof) +
  annotate("text", x = 10, y = 12, label = "low\nproficiency") +
  annotate("text", x = 34, y = 12, label = "high\nproficiency")
```


```{r}
ggplot(ppts %>% filter(Profic_categ != "native"),
       aes(x = ClozeScore, fill = Condition)) +
  geom_histogram(binwidth = 1) +
  geom_vline(xintercept = cutoff_prof) +
  annotate("text", x = 10, y = 5, label = "low\nproficiency") +
  annotate("text", x = 34, y = 5, label = "high\nproficiency")
```

```{r}
# Subset data set and select the variables we need
d_mod_dichot <- d_mod %>% 
  filter(Profic_categ != "medium prof") %>%
  dplyr::select(Subject:cTrial, Profic_categ:Used, Condition_bin)
head(d_mod_dichot)
```

### Coding schemes

Verify factors `Condition_bin` and `VerbType` are contrast coded:

```{r}
# Verify factors are contrast coded:
contrasts(d_mod_dichot$Condition_bin)
contrasts(d_mod_dichot$VerbType)
```

We will use simple coding for `d_mod_dichot$Profic_categ`, so that the model
coefficients compare:

- L2 high vs natives
- L2 low vs natives
- The intercept represents the grand mean of all three conditions

I follow the [IDRE/UCLA tutorial](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#SIMPLE):

(NB: I am not sure this is an orthogonal coding scheme and what consequences
this has, especially when involving higher-order interactions.)

```{r}
# order factor levels
d_mod_dichot$Profic_categ <- factor(d_mod_dichot$Profic_categ,
                                    levels = c("native", "high prof", "low prof"))
# set contrasts
mysimple <- matrix(c(-1/3, 2/3, -1/3,
                     -1/3, -1/3, 2/3), 
                   ncol = 2)
mysimple
contrasts(d_mod_dichot$Profic_categ) <- mysimple
colnames(contrasts(d_mod_dichot$Profic_categ)) <- c("L2hi_vs_NS", "L2lo_vs_NS")
contrasts(d_mod_dichot$Profic_categ)
```


### GLMM fitting -- using data from all trials

GLMM with RE structure closest to the GAMM (see section 4.2.2):

```{r WP1614}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_L1L2_dichot_prof.expr <- "glmer(Used ~
    Profic_categ * VerbType * Condition_bin * cTrial +
    (1 + cTrial | Subject) + (1 | VideoName),
  data = d_mod_dichot, family = 'binomial',
  control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_L1L2_dichot_prof", glmm_L1L2_dichot_prof.expr)
```


The model above fails to converge. Following Florian's advice, we fit a model
constraining the correlation between random intercept and slope to be 0
using the double-bar (`||`) syntax.
(Florian's email 2018-08-17: "The || orthogonalize the different components
(assuming a covariance of 0), which often converges and tends to *not* result
in anti-conservativity.)"

Upon reading the lme4 vignette (Bates et al., 2015, *J Stat Softw*), however,
it seems to me that this simplified model could have some drawbacks. This
is not based on my understanding of the underlying maths, but more superficially
on the following passage in Bates et al.:

"The use of models [where random slopes and intercepts are assumed independent]
should ideally be restricted to cases where the predictor is measured on a
ratio scale (i.e., the zero point on the scale is meaningful, not just a 
location defined by convenience or convention)..." (p.8)

In our case, however, the zero point of `cTrial` is not especially meaningful:
it denotes the centred number of trial (i.e., the middle of the experiment
or, in this case, the middle of the trials selected for analysis). Here is how
the authors describe the subtle drawback of this simplification:

"Models in which the slopes and intercepts are allowed to have a nonzero
correlation [...] are invariant to additive shifts of the continuous predictor
[...]. This invariance breaks down when the correlation is constrained to zero;
any shift in the predictor will necessarily lead to a change in the estimated
correlation, and in the likelihood and predictions of the model." (ibid.)

I don't have a clue if this is a concern in our case.


```{r}
# Random by-subject/item intercepts and random by-subject slope for cTrial.
# Expression to be passed to the load_or_fit function:
glmm_L1L2_dichot_prof_no_corr.expr <- "glmer(Used ~
    Profic_categ * VerbType * Condition_bin * cTrial +
    (1 + cTrial || Subject) + (1 | VideoName),
  data = d_mod_dichot, family = 'binomial',
  control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_L1L2_dichot_prof_no_corr", glmm_L1L2_dichot_prof_no_corr.expr)
```


```{r, echo = FALSE}
# glmm_L1L2_dichot_prof_min.expr <- "glmer(Used ~
#     Profic_categ * VerbType * Condition_bin * cTrial +
#     (1 | Subject) + (1 | VideoName),
#   data = d_mod_dichot, family = 'binomial',
#   control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# # load model or fit it
# load_or_fit("glmm_L1L2_dichot_prof_min", glmm_L1L2_dichot_prof_min.expr)
```


Summary of the model that also has a random by-subject slope for `cTrial`
(see immediately below for a more readable output):

```{r}
summary(glmm_L1L2_dichot_prof)
```


```{r}
summary(glmm_L1L2_dichot_prof_no_corr)
```



TO DO (update pasted output!)

```
> summary(glmm_L1L2_dichot_prof_trial)

```


### Embedding under `VerbType`

Following Florian's suggestion (2018-08-19), we fit a nested model so that
the effect of priming and its interactions are nested under condition:

```{r}
# Expression to be passed to the load_or_fit function:
glmm_L1L2_dichot_prof_no_corr_embed.expr <- "glmer(Used ~ 
     VerbType / (Profic_categ * Condition_bin * cTrial) +
    (1 + cTrial || Subject) + (1 | VideoName),
  data = d_mod_dichot, family = 'binomial',
  control = glmerControl(optimizer='bobyqa', optCtrl=list(maxfun=2e5)))"
# load model or fit it
load_or_fit("glmm_L1L2_dichot_prof_no_corr_embed", glmm_L1L2_dichot_prof_no_corr_embed.expr)
```

```{r}
summary(glmm_L1L2_dichot_prof_no_corr_embed)
```




### Model interpretation


Quick and dirty plot

```{r}
glmm_L1L2_dichot_prof_no_corr_predicted <- data.frame(d_mod_dichot, Predicted = predict(glmm_L1L2_dichot_prof_no_corr))
glmm_L1L2_dichot_prof_no_corr_predicted %>%
  group_by(Condition_bin, VerbType, Profic_categ, Trial) %>%
  summarise(Y = mean(Predicted)) %>%
  ggplot(aes(x = Trial, y = Y, shape = Condition_bin, colour = VerbType)) +
  geom_point() +
  geom_line() +
  facet_grid(. ~ Profic_categ)
```

The two models above yield very similar estimates. The model that includes
`cTrial` as a random by-subject slope gives a convergence failure message,
but its value for `max|grad|` (whatever it means) is very close to the threshold
`tol`, so it might not be reason for great alarm.

None of the models strongly supports the conclusion that high proficiency L2
speakers resemble native speakers, while low proficiency L2 speakers differ 
from natives.
In fact, the pattern of results suggests the opposite: that high proficiency
L2 speakers differ more from natives than low proficiency L2ers.
This is not easy reconcile with the pattern of results in the GAMMs.
Perhaps what is hapeening here is that low proficiency L2ers are more
variable than high proficiency L2ers, so that no differences become apparent,
whereas reduced variability in high proficiency L2ers makes differences
from the natives detectable.


## Conclusion

The pattern of results suggested by the GAMMs we fit to answer Question 3
are not strongly corroborated by the GLMM analysis.




Alternatives to double-counting baseline participants
=================================================

(See Florian's email from 20 augusti 2018 23:57; 
Subject: Re: draft L2 priming/adaptation paper for BLC)


## Treat Path/Manner as binomial choice

TFJ:

"alternative option 2: If there's very little data for the latter two cases (neither, both), one could just exclude those and then treat it as a binomial choice (with some checks to make sure that this exclusion doesn't drive the results). That would be a common and easier to interpret solution (e.g., almost all production experiments I know do something like this when they really should be doing multinomial analyses), but you'd be throwing away data."

How many observations of each type are there?

```{r}
d$DV_multinom <- with(d, ifelse(P_V == 0 & M_V == 0, "None",
                                ifelse(P_V == 1 & M_V == 0, "P-verb",
                                       ifelse(P_V == 0 & M_V == 1, "M-verb", "Both"))))
with(d, table(Group, DV_multinom, useNA = "ifany"))
mytb <- with(d, addmargins(table(Group, DV_multinom, useNA = "ifany")))
```

We'd be throwing away:

- `r round(100 * (mytb[3,1] + mytb[3,3]) / mytb[3,5], 1)`% of all data:
- `r round(100 * (mytb[2,1] + mytb[2,3]) / mytb[2,5], 1)`% from native speakers, and
- `r round(100 * (mytb[1,1] + mytb[1,3]) / mytb[1,5], 1)`% from L2ers.



